{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47a3f39",
   "metadata": {},
   "source": [
    "# Humans with special needs reviews extraction \n",
    "\n",
    "The objective is to extract relevant reviews to understand the profiles of travelers with special needs such as wheelchair, handicap, baby or children."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2b5f8",
   "metadata": {},
   "source": [
    "### Word regex extraction\n",
    "\n",
    "The keywords list is not exhaustive but tend to extract the main part of the targeted reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f23f3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcfd06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df_booking = pl.read_csv('../data/processed/data_totale_booking.csv')\n",
    "df_yelp = pl.read_ndjson('../data/original/yelp_dataset/yelp_academic_dataset_review.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e30138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key words\n",
    "categories = {\n",
    "    \"handicap\": [\n",
    "        \"handicap\", \"wheelchair\", \"accessible\", \"braille\", \"ramp\", \"lift\", \"elevator\",\n",
    "        \"disabled\", \"barrier-free\", \"accessible toilet\", \"toilet accessible\",\n",
    "        \"mobility aid\", \"adapted\", \"hearing aid\", \"visual impairment\", \"accessible entrance\"\n",
    "    ],\n",
    "    \"children\": [\n",
    "        \"child\", \"baby\", \"kid\", \"stroller\", \"son\", \"daughter\", \"toddler\",\n",
    "        \"infant\", \"playground\", \"high chair\", \"changing table\", \"family-friendly\",\n",
    "        \"childcare\", \"kids menu\", \"baby seat\", \"family\",\"baby bed\", \"cot\", \"crib\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3ae8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Lemmatization ###################### \n",
    "\n",
    "# Load the english model of SpaCy\n",
    "# spacy.prefer_gpu()            # To uncomment to run on GPU\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Lemmatization via SpaCy\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text.lower())  # minuscules + NLP\n",
    "    return \" \".join(token.lemma_ for token in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "705ed961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'handicap': ['handicap', 'wheelchair', 'accessible', 'braille', 'ramp', 'lift', 'elevator', 'disable', 'barrier - free', 'accessible toilet', 'toilet accessible', 'mobility aid', 'adapt', 'hear aid', 'visual impairment', 'accessible entrance'], 'children': ['child', 'baby', 'kid', 'stroller', 'son', 'daughter', 'toddler', 'infant', 'playground', 'high chair', 'change table', 'family - friendly', 'childcare', 'kids menu', 'baby seat', 'family', 'baby bed', 'cot', 'crib']}\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize categories so that words can match each other.\n",
    "lemmatized_categories = {\n",
    "    category: [lemmatize_text(kw) for kw in keywords]\n",
    "    for category, keywords in categories.items()\n",
    "}\n",
    "\n",
    "print(lemmatized_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab501156",
   "metadata": {},
   "source": [
    "### Booking dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "866e96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_booking.head(10000)\n",
    "\n",
    "df_lemmatized = df_test.with_columns([\n",
    "    pl.col(\"review_positive\").map_elements(lemmatize_text).alias(\"review_positive\"),\n",
    "    pl.col(\"review_negative\").map_elements(lemmatize_text).alias(\"review_negative\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71923047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Category Count ===\n",
      "\n",
      "handicap: 349\n",
      "children: 602\n",
      "\n",
      "=== Keyword Details ===\n",
      "\n",
      "family: 288\n",
      "lift: 146\n",
      "elevator: 133\n",
      "kid: 127\n",
      "child: 72\n",
      "accessible: 51\n",
      "son: 37\n",
      "baby: 24\n",
      "daughter: 22\n",
      "playground: 10\n",
      "wheelchair: 9\n",
      "cot: 7\n",
      "toddler: 7\n",
      "ramp: 6\n",
      "stroller: 4\n",
      "crib: 2\n",
      "disable: 2\n",
      "adapt: 1\n",
      "handicap: 1\n",
      "high chair: 1\n",
      "infant: 1\n",
      "accessible entrance: 0\n",
      "accessible toilet: 0\n",
      "baby bed: 0\n",
      "baby seat: 0\n",
      "barrier - free: 0\n",
      "braille: 0\n",
      "change table: 0\n",
      "childcare: 0\n",
      "family - friendly: 0\n",
      "hear aid: 0\n",
      "kids menu: 0\n",
      "mobility aid: 0\n",
      "toilet accessible: 0\n",
      "visual impairment: 0\n"
     ]
    }
   ],
   "source": [
    "# Concatenate both review columns into a single text column for counting/filtering\n",
    "df_lemmatized = df_lemmatized.with_columns(\n",
    "    (pl.col(\"review_positive\") + \" \" + pl.col(\"review_negative\")).alias(\"text\")\n",
    ")\n",
    "\n",
    "# Dictionnaires pour les comptages\n",
    "keyword_summary = {}\n",
    "category_summary = {}\n",
    "\n",
    "# Dictionnaire pour stocker les DataFrames filtrés par catégorie\n",
    "filtered_dfs = {}\n",
    "\n",
    "for category, keywords in lemmatized_categories.items():\n",
    "    category_total = 0\n",
    "    \n",
    "    # Construire la regex de recherche\n",
    "    regex = r\"\\b(\" + \"|\".join(\n",
    "        re.escape(kw).replace(\"\\\\-\", \"[-\\\\s]\").replace(\"\\\\ \", \"\\\\s+\")\n",
    "        for kw in keywords\n",
    "    ) + r\")\\b\"\n",
    "\n",
    "    # Filtrer les lignes contenant au moins un mot-clé\n",
    "    matches = df_lemmatized.filter(pl.col(\"text\").str.contains(regex))\n",
    "\n",
    "    # Fonction pour identifier les mots-clés trouvés\n",
    "    def find_keywords(text):\n",
    "        found = [\n",
    "            kw for kw in keywords\n",
    "            if re.search(r\"\\b\" + re.escape(kw).replace(\"\\\\ \", \"\\\\s+\") + r\"\\b\", text)\n",
    "        ]\n",
    "        return \", \".join(found)\n",
    "\n",
    "    # Ajouter la colonne des mots-clés trouvés\n",
    "    matches = matches.with_columns(\n",
    "        pl.col(\"text\").map_elements(find_keywords).alias(\"keywords_found\")\n",
    "    )\n",
    "\n",
    "    # Sauvegarder ce DataFrame dans un dictionnaire\n",
    "    filtered_dfs[category] = matches\n",
    "\n",
    "    # Comptage des mots-clés\n",
    "    for kw in keywords:\n",
    "        count = (\n",
    "            df_lemmatized\n",
    "            .select(pl.col(\"text\").str.count_matches(\n",
    "                r\"\\b\" + re.escape(kw).replace(\"\\\\ \", \"\\\\s+\") + r\"\\b\"\n",
    "            ).sum().alias(\"total\"))\n",
    "            .item()\n",
    "        )\n",
    "        keyword_summary[kw] = int(count)\n",
    "        category_total += count\n",
    "\n",
    "    category_summary[category] = int(category_total)\n",
    "\n",
    "# === Impression du résumé ===\n",
    "print(\"\\n=== Category Count ===\\n\")\n",
    "for cat, count in category_summary.items():\n",
    "    print(f\"{cat}: {count}\")\n",
    "\n",
    "print(\"\\n=== Keyword Details ===\\n\")\n",
    "for kw, count in sorted(keyword_summary.items(), key=lambda x: (-x[1], x[0])):\n",
    "    print(f\"{kw}: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3179cac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save : ../data/processed/data_handicap_booking.csv (301 lignes)\n",
      "\n",
      "Save : ../data/processed/data_children_booking.csv (455 lignes)\n"
     ]
    }
   ],
   "source": [
    "# To save the new datasets\n",
    "for cat, df_cat in filtered_dfs.items():\n",
    "    filename = f\"../data/processed/data_{cat}_booking.csv\"\n",
    "    df_cat.select([c for c in df_cat.columns if c != \"text\"]).write_csv(filename)\n",
    "    print(f\"\\nSave : {filename} ({df_cat.shape[0]} lignes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04abf92b",
   "metadata": {},
   "source": [
    "### Yelp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6538c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_yelp.head(10000)\n",
    "\n",
    "df_lemmatized = df_test.with_columns(\n",
    "    pl.col(\"text\").map_elements(lemmatize_text).alias(\"text\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9a17e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Category Count ===\n",
      "\n",
      "handicap: 109\n",
      "children: 1517\n",
      "\n",
      "=== Keyword Details ===\n",
      "\n",
      "family: 522\n",
      "kid: 428\n",
      "son: 149\n",
      "child: 142\n",
      "daughter: 135\n",
      "baby: 95\n",
      "elevator: 51\n",
      "lift: 20\n",
      "accessible: 13\n",
      "stroller: 13\n",
      "toddler: 12\n",
      "ramp: 9\n",
      "playground: 8\n",
      "wheelchair: 8\n",
      "handicap: 5\n",
      "infant: 5\n",
      "high chair: 3\n",
      "adapt: 2\n",
      "cot: 2\n",
      "crib: 2\n",
      "change table: 1\n",
      "disable: 1\n",
      "accessible entrance: 0\n",
      "accessible toilet: 0\n",
      "baby bed: 0\n",
      "baby seat: 0\n",
      "barrier - free: 0\n",
      "braille: 0\n",
      "childcare: 0\n",
      "family - friendly: 0\n",
      "hear aid: 0\n",
      "kids menu: 0\n",
      "mobility aid: 0\n",
      "toilet accessible: 0\n",
      "visual impairment: 0\n"
     ]
    }
   ],
   "source": [
    "# Dictionnaires pour les comptages\n",
    "keyword_summary = {}\n",
    "category_summary = {}\n",
    "\n",
    "# Dictionnaire pour stocker les DataFrames filtrés par catégorie\n",
    "filtered_dfs = {}\n",
    "\n",
    "for category, keywords in lemmatized_categories.items():\n",
    "    category_total = 0\n",
    "    \n",
    "    # Construire la regex de recherche\n",
    "    regex = r\"\\b(\" + \"|\".join(\n",
    "        re.escape(kw).replace(\"\\\\-\", \"[-\\\\s]\").replace(\"\\\\ \", \"\\\\s+\")\n",
    "        for kw in keywords\n",
    "    ) + r\")\\b\"\n",
    "\n",
    "    # Filtrer les lignes contenant au moins un mot-clé\n",
    "    matches = df_lemmatized.filter(pl.col(\"text\").str.contains(regex))\n",
    "\n",
    "    # Fonction pour identifier les mots-clés trouvés\n",
    "    def find_keywords(text):\n",
    "        found = [\n",
    "            kw for kw in keywords\n",
    "            if re.search(r\"\\b\" + re.escape(kw).replace(\"\\\\ \", \"\\\\s+\") + r\"\\b\", text)\n",
    "        ]\n",
    "        return \", \".join(found)\n",
    "\n",
    "    # Ajouter la colonne des mots-clés trouvés\n",
    "    matches = matches.with_columns(\n",
    "        pl.col(\"text\").map_elements(find_keywords).alias(\"keywords_found\")\n",
    "    )\n",
    "\n",
    "    # Sauvegarder ce DataFrame dans un dictionnaire\n",
    "    filtered_dfs[category] = matches\n",
    "\n",
    "    # Comptage des mots-clés\n",
    "    for kw in keywords:\n",
    "        count = (\n",
    "            df_lemmatized\n",
    "            .select(pl.col(\"text\").str.count_matches(\n",
    "                r\"\\b\" + re.escape(kw).replace(\"\\\\ \", \"\\\\s+\") + r\"\\b\"\n",
    "            ).sum().alias(\"total\"))\n",
    "            .item()\n",
    "        )\n",
    "        keyword_summary[kw] = int(count)\n",
    "        category_total += count\n",
    "\n",
    "    category_summary[category] = int(category_total)\n",
    "\n",
    "# === Impression du résumé ===\n",
    "print(\"\\n=== Category Count ===\\n\")\n",
    "for cat, count in category_summary.items():\n",
    "    print(f\"{cat}: {count}\")\n",
    "\n",
    "print(\"\\n=== Keyword Details ===\\n\")\n",
    "for kw, count in sorted(keyword_summary.items(), key=lambda x: (-x[1], x[0])):\n",
    "    print(f\"{kw}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "350c9da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save : ../data/processed/data_handicap_yelp.csv (84 lignes)\n",
      "\n",
      "Save : ../data/processed/data_children_yelp.csv (1004 lignes)\n"
     ]
    }
   ],
   "source": [
    "# To save the new datasets\n",
    "for cat, df_cat in filtered_dfs.items():\n",
    "    filename = f\"../data/processed/data_{cat}_yelp.csv\"\n",
    "    df_cat.select([c for c in df_cat.columns if c != \"text\"]).write_csv(filename)\n",
    "    print(f\"\\nSave : {filename} ({df_cat.shape[0]} lignes)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
