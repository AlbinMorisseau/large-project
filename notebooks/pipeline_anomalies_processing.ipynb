{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e2536e8",
   "metadata": {},
   "source": [
    "# Pipeline to manage anomalies processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba5131a",
   "metadata": {},
   "source": [
    "Before using any dataset, it is necessary to clean the data to obtain a clear, formatted, and complete dataset. This tedious step is the first step in data analysis.\n",
    "\n",
    "In this notebook, there are building blocks (functions) that can be used later to perform the identified preprocessing steps.\n",
    "\n",
    "- Remove missing values\n",
    "- Remove duplicates\n",
    "- Remove special characters\n",
    "- Convert numbers to letters\n",
    "- Identify the language of the review and translate it if necessary\n",
    "- Correct spelling errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7caac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import re\n",
    "from num2words import num2words\n",
    "import langid\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from deep_translator import GoogleTranslator\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd4736d",
   "metadata": {},
   "source": [
    "## Remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735da6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_missing_values(df: pl.DataFrame, column_name: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove rows from a DataFrame where the specified column has missing values,\n",
    "    and return the cleaned DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pl.DataFrame): The DataFrame to clean.\n",
    "        column_name (str): Column to check for missing values.\n",
    "        \n",
    "    Returns:\n",
    "        pl.DataFrame: Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # Drop rows where the specified column is null\n",
    "    df_clean = df.drop_nulls(subset=[column_name])\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d33393ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3363667, 5)\n",
      "(2835129, 5)\n"
     ]
    }
   ],
   "source": [
    "# Example of use\n",
    "df = pl.read_csv(\"../data/processed/all_reviews.csv\")\n",
    "df_clean_missing_values = clean_missing_values(df, \"review\")\n",
    "print(df.shape)\n",
    "print(df_clean_missing_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17059c65",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8caa955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df: pl.DataFrame, subset_columns: list) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove duplicate rows from a DataFrame based on specified columns,\n",
    "    and return the cleaned DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pl.DataFrame): The DataFrame to clean.\n",
    "        subset_columns (list): List of columns to consider for duplicates.\n",
    "        \n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    # Drop duplicates based on the subset of columns\n",
    "    df_clean = df.unique(subset=subset_columns)\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a73d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2835129, 5)\n",
      "(2811720, 5)\n"
     ]
    }
   ],
   "source": [
    "# Example of use\n",
    "df_clean_duplicates = remove_duplicates(df_clean_missing_values, \"review\")\n",
    "print(df_clean_missing_values.shape)\n",
    "print(df_clean_duplicates.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2373ce80",
   "metadata": {},
   "source": [
    "## Remove spacial characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a391adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(df: pl.DataFrame, column_name: str, keep: str = \"\") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove special characters from a specified text column using regex.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Input Polars DataFrame.\n",
    "        column_name (str): Name of the text column to clean.\n",
    "        keep (str): Optional string of characters to preserve (e.g., \".,\" to keep dots and commas).\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: New DataFrame with cleaned text in the specified column.\n",
    "    \"\"\"\n",
    "    # Build regex dynamically: allow alphanumeric, space, underscore, and chosen extra characters\n",
    "    pattern = rf\"[^\\w\\s{re.escape(keep)}]\"\n",
    "\n",
    "    def clean_text(text: str) -> str:\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return text  # ignore empty or non-string\n",
    "        return re.sub(pattern, \"\", text)\n",
    "\n",
    "    df_cleaned = df.with_columns(\n",
    "        pl.col(column_name).map_elements(clean_text).alias(column_name)\n",
    "    )\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62e8789c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌───────────┬────────────────────────────┬───────────────────────────┬─────────────┬───────────────┐\n",
      "│ id_review ┆ review                     ┆ original_dataset          ┆ original_id ┆ service_type  │\n",
      "│ ---       ┆ ---                        ┆ ---                       ┆ ---         ┆ ---           │\n",
      "│ i64       ┆ str                        ┆ str                       ┆ i64         ┆ str           │\n",
      "╞═══════════╪════════════════════════════╪═══════════════════════════╪═════════════╪═══════════════╡\n",
      "│ 238627    ┆ I have stayed at this      ┆ data_tripadvisor_hotel_re ┆ 11579655    ┆ accommodation │\n",
      "│           ┆ hotel at…                  ┆ views                     ┆             ┆               │\n",
      "│ 3063439   ┆ The booking of rooms being ┆ data_european_hotel_revie ┆ 215511      ┆ accommodation │\n",
      "│           ┆ no…                        ┆ ws                        ┆             ┆               │\n",
      "│ 2505326   ┆ We chose this hotel        ┆ data_booking              ┆ 1490174     ┆ accommodation │\n",
      "│           ┆ because it…                ┆                           ┆             ┆               │\n",
      "│ 2053159   ┆ Very clean, very modern,   ┆ data_booking              ┆ 1038007     ┆ accommodation │\n",
      "│           ┆ perfe…                     ┆                           ┆             ┆               │\n",
      "│ 2525735   ┆ The size, view and         ┆ data_booking              ┆ 1510583     ┆ accommodation │\n",
      "│           ┆ location No…               ┆                           ┆             ┆               │\n",
      "└───────────┴────────────────────────────┴───────────────────────────┴─────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Example of use\n",
    "df_no_special_character = remove_special_characters(df_clean_duplicates, \"review\", \".,!?\")\n",
    "print(df_no_special_character.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f61e8e",
   "metadata": {},
   "source": [
    "## Convert numbers to letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4310662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_to_words(df: pl.DataFrame, column_name: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert all numbers in a text column into words using num2words.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Input DataFrame.\n",
    "        column_name (str): Name of the text column to process.\n",
    "        lang (str): Language code (e.g., 'en' or 'fr').\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: New DataFrame with numbers replaced by words.\n",
    "    \"\"\"\n",
    "    def convert_numbers(text: str) -> str:\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return text\n",
    "        # Replace every number with its text version\n",
    "        return re.sub(r'\\b\\d+\\b', lambda m: num2words(int(m.group())), text)\n",
    "\n",
    "    df_converted = df.with_columns(\n",
    "        pl.col(column_name).map_elements(convert_numbers).alias(column_name)\n",
    "    )\n",
    "\n",
    "    return df_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf13c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌───────────┬────────────────────────────┬───────────────────────────┬─────────────┬───────────────┐\n",
      "│ id_review ┆ review                     ┆ original_dataset          ┆ original_id ┆ service_type  │\n",
      "│ ---       ┆ ---                        ┆ ---                       ┆ ---         ┆ ---           │\n",
      "│ i64       ┆ str                        ┆ str                       ┆ i64         ┆ str           │\n",
      "╞═══════════╪════════════════════════════╪═══════════════════════════╪═════════════╪═══════════════╡\n",
      "│ 238627    ┆ I have stayed at this      ┆ data_tripadvisor_hotel_re ┆ 11579655    ┆ accommodation │\n",
      "│           ┆ hotel at…                  ┆ views                     ┆             ┆               │\n",
      "│ 3063439   ┆ The booking of rooms being ┆ data_european_hotel_revie ┆ 215511      ┆ accommodation │\n",
      "│           ┆ no…                        ┆ ws                        ┆             ┆               │\n",
      "│ 2505326   ┆ We chose this hotel        ┆ data_booking              ┆ 1490174     ┆ accommodation │\n",
      "│           ┆ because it…                ┆                           ┆             ┆               │\n",
      "│ 2053159   ┆ Very clean, very modern,   ┆ data_booking              ┆ 1038007     ┆ accommodation │\n",
      "│           ┆ perfe…                     ┆                           ┆             ┆               │\n",
      "│ 2525735   ┆ The size, view and         ┆ data_booking              ┆ 1510583     ┆ accommodation │\n",
      "│           ┆ location No…               ┆                           ┆             ┆               │\n",
      "└───────────┴────────────────────────────┴───────────────────────────┴─────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Example of use\n",
    "df_without_number = numbers_to_words(df_no_special_character, \"review\")\n",
    "print(df_without_number.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7955e",
   "metadata": {},
   "source": [
    "## Languages and translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b2e3d6",
   "metadata": {},
   "source": [
    "### Languages detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ed3ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language_parallel(df: pl.DataFrame, column_name: str, num_threads: int = 4) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Detect the language of a text column in a Polars DataFrame using langid in parallel.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Input DataFrame.\n",
    "        column_name (str): Name of the text column to process.\n",
    "        num_threads (int): Number of threads to use for parallel processing (default=4).\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: New DataFrame with an added column 'detected_lang' containing language codes.\n",
    "    \"\"\"\n",
    "    def detect_lang(text: str) -> str:\n",
    "        \"\"\"Return the language code of a single text using langid.\"\"\"\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return None\n",
    "        lang, _ = langid.classify(text)\n",
    "        return lang\n",
    "\n",
    "    # Convert the Polars column to a Python list\n",
    "    texts = df[column_name].to_list()\n",
    "\n",
    "    # Parallel processing with ThreadPoolExecutor\n",
    "    all_langs = []\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        for result in tqdm(executor.map(detect_lang, texts), total=len(texts), desc=\"Language detection\"):\n",
    "            all_langs.append(result)\n",
    "\n",
    "    # Return new DataFrame with added column\n",
    "    df_result = df.with_columns(pl.Series(\"detected_lang\", all_langs))\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a54dca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Language detection: 100%|██████████| 100/100 [00:05<00:00, 19.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (4, 2)\n",
      "┌───────────────┬──────────┐\n",
      "│ detected_lang ┆ nb_texts │\n",
      "│ ---           ┆ ---      │\n",
      "│ str           ┆ u32      │\n",
      "╞═══════════════╪══════════╡\n",
      "│ en            ┆ 97       │\n",
      "│ pl            ┆ 1        │\n",
      "│ sv            ┆ 1        │\n",
      "│ it            ┆ 1        │\n",
      "└───────────────┴──────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of use\n",
    "df_new = detect_language_parallel(df.head(100), column_name=\"review\", num_threads=4)\n",
    "counts = df_new.group_by(\"detected_lang\").agg(pl.len().alias(\"nb_texts\")).sort(\"nb_texts\", descending=True)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b4041ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 6)\n",
      "┌───────────┬────────────────────┬────────────────────┬─────────────┬──────────────┬───────────────┐\n",
      "│ id_review ┆ review             ┆ original_dataset   ┆ original_id ┆ service_type ┆ detected_lang │\n",
      "│ ---       ┆ ---                ┆ ---                ┆ ---         ┆ ---          ┆ ---           │\n",
      "│ i64       ┆ str                ┆ str                ┆ i64         ┆ str          ┆ str           │\n",
      "╞═══════════╪════════════════════╪════════════════════╪═════════════╪══════════════╪═══════════════╡\n",
      "│ 61        ┆ Relaxing,          ┆ data_activities_re ┆ 62          ┆ leisure      ┆ it            │\n",
      "│           ┆ Swimming,          ┆ views              ┆             ┆              ┆               │\n",
      "│           ┆ vacationin…        ┆                    ┆             ┆              ┆               │\n",
      "│ 77        ┆ Bingo   Space   TV ┆ data_activities_re ┆ 78          ┆ leisure      ┆ pl            │\n",
      "│           ┆                    ┆ views              ┆             ┆              ┆               │\n",
      "│ 97        ┆ Sledding, tv,      ┆ data_activities_re ┆ 98          ┆ leisure      ┆ sv            │\n",
      "│           ┆ bonfire            ┆ views              ┆             ┆              ┆               │\n",
      "└───────────┴────────────────────┴────────────────────┴─────────────┴──────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "non_english_reviews = df_new.filter(pl.col(\"detected_lang\") != \"en\")\n",
    "print(non_english_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de40e2c5",
   "metadata": {},
   "source": [
    "### Translation in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfaf2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_non_english_parallel(df: pl.DataFrame, column_name: str, detected_lang_col: str = \"detected_lang\", num_threads: int = 4) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Translate texts in a Polars DataFrame column to English in parallel, only for texts detected in a language other than English.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Input DataFrame.\n",
    "        column_name (str): Name of the text column to translate.\n",
    "        detected_lang_col (str): Name of the column containing detected language codes (default='detected_lang').\n",
    "        num_threads (int): Number of threads to use for parallel translation (default=4).\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: New DataFrame with an added column 'translated_text' containing English translations.\n",
    "                      Texts already in English are kept unchanged.\n",
    "    \"\"\"\n",
    "    # Initialize the translator\n",
    "    translator = GoogleTranslator(source='auto', target='en')\n",
    "\n",
    "    def translate_one(text: str) -> str:\n",
    "        \"\"\"Translate a single text to English, return the text unchanged if empty or already in English.\"\"\"\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return text\n",
    "        try:\n",
    "            return translator.translate(text)\n",
    "        except Exception as e:\n",
    "            return f\"[ERROR: {e}]\"\n",
    "\n",
    "    # Prepare texts to translate\n",
    "    texts_to_translate = []\n",
    "    indices_to_translate = []\n",
    "    for i, (text, lang) in enumerate(zip(df[column_name].to_list(), df[detected_lang_col].to_list())):\n",
    "        if lang != 'en':\n",
    "            texts_to_translate.append(text)\n",
    "            indices_to_translate.append(i)\n",
    "\n",
    "    # Parallel translation\n",
    "    translated_texts = [None] * df.height\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        for idx, result in zip(indices_to_translate, tqdm(executor.map(translate_one, texts_to_translate), total=len(texts_to_translate), desc=\"Translating non-English\")):\n",
    "            translated_texts[idx] = result\n",
    "\n",
    "    # Fill in English texts unchanged\n",
    "    for i in range(df.height):\n",
    "        if translated_texts[i] is None:\n",
    "            translated_texts[i] = df[column_name][i]\n",
    "\n",
    "    # Return new DataFrame with added column\n",
    "    df_result = df.with_columns(pl.Series(\"translated_text\", translated_texts))\n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "068a8ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating non-English:  67%|██████▋   | 2/3 [00:01<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (100, 7)\n",
      "┌───────────┬──────────────┬──────────────┬─────────────┬──────────────┬─────────────┬─────────────┐\n",
      "│ id_review ┆ review       ┆ original_dat ┆ original_id ┆ service_type ┆ detected_la ┆ translated_ │\n",
      "│ ---       ┆ ---          ┆ aset         ┆ ---         ┆ ---          ┆ ng          ┆ text        │\n",
      "│ i64       ┆ str          ┆ ---          ┆ i64         ┆ str          ┆ ---         ┆ ---         │\n",
      "│           ┆              ┆ str          ┆             ┆              ┆ str         ┆ str         │\n",
      "╞═══════════╪══════════════╪══════════════╪═════════════╪══════════════╪═════════════╪═════════════╡\n",
      "│ 0         ┆ fishing ,    ┆ data_activit ┆ 1           ┆ leisure      ┆ en          ┆ fishing ,   │\n",
      "│           ┆ swimming ,   ┆ ies_reviews  ┆             ┆              ┆             ┆ swimming ,  │\n",
      "│           ┆ traveling    ┆              ┆             ┆              ┆             ┆ traveling   │\n",
      "│ 1         ┆ Snowball     ┆ data_activit ┆ 2           ┆ leisure      ┆ en          ┆ Snowball    │\n",
      "│           ┆ fight        ┆ ies_reviews  ┆             ┆              ┆             ┆ fight       │\n",
      "│           ┆ Skiing       ┆              ┆             ┆              ┆             ┆ Skiing      │\n",
      "│           ┆ Snowbo…      ┆              ┆             ┆              ┆             ┆ Snowbo…     │\n",
      "│ 2         ┆ Great Book!: ┆ data_activit ┆ 3           ┆ leisure      ┆ en          ┆ Great       │\n",
      "│           ┆ This is a    ┆ ies_reviews  ┆             ┆              ┆             ┆ Book!: This │\n",
      "│           ┆ great b…     ┆              ┆             ┆              ┆             ┆ is a great  │\n",
      "│           ┆              ┆              ┆             ┆              ┆             ┆ b…          │\n",
      "│ 3         ┆ Far from the ┆ data_activit ┆ 4           ┆ leisure      ┆ en          ┆ Far from    │\n",
      "│           ┆ Peppers'     ┆ ies_reviews  ┆             ┆              ┆             ┆ the         │\n",
      "│           ┆ best.: I…    ┆              ┆             ┆              ┆             ┆ Peppers'    │\n",
      "│           ┆              ┆              ┆             ┆              ┆             ┆ best.: I…   │\n",
      "│ 4         ┆ Bonefire,    ┆ data_activit ┆ 5           ┆ leisure      ┆ en          ┆ Bonefire,   │\n",
      "│           ┆ camping,     ┆ ies_reviews  ┆             ┆              ┆             ┆ camping,    │\n",
      "│           ┆ drinking     ┆              ┆             ┆              ┆             ┆ drinking    │\n",
      "│ …         ┆ …            ┆ …            ┆ …           ┆ …            ┆ …           ┆ …           │\n",
      "│ 95        ┆ NOT          ┆ data_activit ┆ 96          ┆ leisure      ┆ en          ┆ NOT         │\n",
      "│           ┆ WIRELESS:    ┆ ies_reviews  ┆             ┆              ┆             ┆ WIRELESS:   │\n",
      "│           ┆ The speakers ┆              ┆             ┆              ┆             ┆ The         │\n",
      "│           ┆ com…         ┆              ┆             ┆              ┆             ┆ speakers    │\n",
      "│           ┆              ┆              ┆             ┆              ┆             ┆ com…        │\n",
      "│ 96        ┆ Coffee       ┆ data_activit ┆ 97          ┆ leisure      ┆ en          ┆ Coffee      │\n",
      "│           ┆ Halloween    ┆ ies_reviews  ┆             ┆              ┆             ┆ Halloween   │\n",
      "│ 97        ┆ Sledding,    ┆ data_activit ┆ 98          ┆ leisure      ┆ sv          ┆ Sledding,   │\n",
      "│           ┆ tv, bonfire  ┆ ies_reviews  ┆             ┆              ┆             ┆ tv, bonfire │\n",
      "│ 98        ┆ fishing,swim ┆ data_activit ┆ 99          ┆ leisure      ┆ en          ┆ fishing,swi │\n",
      "│           ┆ ming,camping ┆ ies_reviews  ┆             ┆              ┆             ┆ mming,campi │\n",
      "│           ┆              ┆              ┆             ┆              ┆             ┆ ng          │\n",
      "│ 99        ┆ Swimming     ┆ data_activit ┆ 100         ┆ leisure      ┆ en          ┆ Swimming    │\n",
      "│           ┆ Hiking       ┆ ies_reviews  ┆             ┆              ┆             ┆ Hiking      │\n",
      "│           ┆ Sleeping     ┆              ┆             ┆              ┆             ┆ Sleeping    │\n",
      "└───────────┴──────────────┴──────────────┴─────────────┴──────────────┴─────────────┴─────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of use \n",
    "df_translated = translate_non_english_parallel(df_new, column_name=\"review\", detected_lang_col=\"detected_lang\", num_threads=4)\n",
    "print(df_translated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e047051",
   "metadata": {},
   "source": [
    "## Correction of spelling error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa45c3e3",
   "metadata": {},
   "source": [
    "### Tests/ Expertimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa915458",
   "metadata": {},
   "source": [
    "Two methods with two libraries are available. Spellchecker seems to perform slightly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02fe20c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like eat appeals\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def textblob_correct(text):\n",
    "    blob = TextBlob(text)\n",
    "    return str(blob.correct())\n",
    "\n",
    "print(textblob_correct(\"I liek eat appels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "014f041b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like eat apples\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spelling = SpellChecker()\n",
    "\n",
    "def spelling_checks(text):\n",
    "    correct_result = []\n",
    "    typo_words = spelling.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in typo_words:\n",
    "            correct_result.append(spelling.correction(word))\n",
    "        else:\n",
    "            correct_result.append(word)\n",
    "    return \" \".join(correct_result)\n",
    "\n",
    "print(spelling_checks(\"I liek eat appels\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3b4e1b",
   "metadata": {},
   "source": [
    "### Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9a88412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling_optimized(df: pl.DataFrame, column_name: str, batch_size: int = 10000) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply fast spell correction on a text column of a large Polars DataFrame.\n",
    "    Uses caching and batch processing for performance.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Input Polars DataFrame.\n",
    "        column_name (str): Column containing text to correct.\n",
    "        batch_size (int): Number of rows to process per batch (default=10,000).\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame with corrected text in the specified column.\n",
    "    \"\"\"\n",
    "    spell = SpellChecker()\n",
    "    cache = {}\n",
    "\n",
    "    def fix_word(word: str) -> str:\n",
    "        \"\"\"Return cached or corrected version of a single word.\"\"\"\n",
    "        if word in cache:\n",
    "            return cache[word]\n",
    "        if word in spell:\n",
    "            cache[word] = word\n",
    "        else:\n",
    "            corrected = spell.correction(word)\n",
    "            cache[word] = corrected if corrected is not None else word\n",
    "        return cache[word]\n",
    "\n",
    "    def fix_text(text: str) -> str:\n",
    "        \"\"\"Apply correction to an entire review.\"\"\"\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return text\n",
    "        words = text.split()\n",
    "        return \" \".join(fix_word(w) for w in words)\n",
    "\n",
    "    # Batch processing\n",
    "    corrected_reviews = []\n",
    "    num_rows = len(df)\n",
    "\n",
    "    for i in tqdm(range(0, num_rows, batch_size), desc=\"Spell-checking in batches\"):\n",
    "        batch = df.slice(i, batch_size)\n",
    "        corrected_batch = [fix_text(t) for t in batch[column_name]]\n",
    "        corrected_reviews.extend(corrected_batch)\n",
    "\n",
    "    # Return new DataFrame with corrected text\n",
    "    df_corrected = df.with_columns(\n",
    "        pl.Series(name=column_name, values=corrected_reviews)\n",
    "    )\n",
    "\n",
    "    return df_corrected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50905187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spell-checking in batches: 100%|██████████| 1/1 [01:50<00:00, 110.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 5)\n",
      "┌───────────┬────────────────────────┬───────────────────────────────┬─────────────┬───────────────┐\n",
      "│ id_review ┆ review                 ┆ original_dataset              ┆ original_id ┆ service_type  │\n",
      "│ ---       ┆ ---                    ┆ ---                           ┆ ---         ┆ ---           │\n",
      "│ i64       ┆ str                    ┆ str                           ┆ i64         ┆ str           │\n",
      "╞═══════════╪════════════════════════╪═══════════════════════════════╪═════════════╪═══════════════╡\n",
      "│ 238627    ┆ I have stayed at this  ┆ data_tripadvisor_hotel_review ┆ 11579655    ┆ accommodation │\n",
      "│           ┆ hotel at…              ┆ s                             ┆             ┆               │\n",
      "│ 3063439   ┆ The booking of rooms   ┆ data_european_hotel_reviews   ┆ 215511      ┆ accommodation │\n",
      "│           ┆ being non…             ┆                               ┆             ┆               │\n",
      "│ 2505326   ┆ We chose this hotel    ┆ data_booking                  ┆ 1490174     ┆ accommodation │\n",
      "│           ┆ because it…            ┆                               ┆             ┆               │\n",
      "│ 2053159   ┆ Very clean very modern ┆ data_booking                  ┆ 1038007     ┆ accommodation │\n",
      "│           ┆ perfect…               ┆                               ┆             ┆               │\n",
      "│ 2525735   ┆ The size view and      ┆ data_booking                  ┆ 1510583     ┆ accommodation │\n",
      "│           ┆ location No …          ┆                               ┆             ┆               │\n",
      "└───────────┴────────────────────────┴───────────────────────────────┴─────────────┴───────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of use\n",
    "df_correct_spelling = correct_spelling_optimized(df_without_number.head(100), \"review\")\n",
    "print(df_correct_spelling.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55671f98",
   "metadata": {},
   "source": [
    "## Number of reviews per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15e36b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2811720, 5)\n",
      "                    original_dataset  nb_lignes\n",
      "0               data_hotel_reviews_1      34393\n",
      "1            data_activities_reviews      45874\n",
      "2   data_european_restaurant_reviews       1426\n",
      "3               data_hotel_reviews_2       9906\n",
      "4             data_airline_reviews_2       8099\n",
      "5        data_european_hotel_reviews     499288\n",
      "6          data_restaurant_reviews_2       9330\n",
      "7                       data_booking    1301650\n",
      "8          data_restaurant_reviews_1        996\n",
      "9               data_hotel_reviews_3       9653\n",
      "10            data_airline_reviews_1       3692\n",
      "11    data_tripadvisor_hotel_reviews     877413\n",
      "12                      data_twitter      10000\n",
      "[Int64, String, String, Int64, String]\n"
     ]
    }
   ],
   "source": [
    "df = df_without_number\n",
    "result = df.group_by(\"original_dataset\").agg(pl.len().alias(\"nb_lignes\"))\n",
    "\n",
    "print(df.shape)\n",
    "print (result.to_pandas())\n",
    "print(df.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
