{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47a3f39",
   "metadata": {},
   "source": [
    "# Pets reviews extraction \n",
    "\n",
    "The objective is to extract relevant reviews to understand the profiles of travelers with pets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2b5f8",
   "metadata": {},
   "source": [
    "## Word regex extraction\n",
    "\n",
    "The keywords list is not exhaustive but tend to extract the main part of the targeted reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f23f3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcfd06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df_booking = pl.read_csv('../data/processed/data_totale_booking.csv')\n",
    "df_yelp = pl.read_ndjson('../data/original/yelp_dataset/yelp_academic_dataset_review.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08e30138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key words\n",
    "categories = {\n",
    "    \"pets\": [\n",
    "        \"dog\", \"cat\", \"pet\", \"animal\", \"rabbit\", \"hamster\", \"ferret\", \"bird\", \"pet-friendly\",\n",
    "        \"animals allowed\", \"dog-friendly\", \"cat-friendly\", \"pet welcome\", \"pup\", \"dog bowl\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92037f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "\n",
    "# Load the english model of SpaCy\n",
    "# spacy.prefer_gpu()            # To uncomment to run on GPU\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Lemmatization via SpaCy\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text.lower())  # minuscules + NLP\n",
    "    return \" \".join(token.lemma_ for token in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize categories so that words can match each other.\n",
    "lemmatized_categories = {\n",
    "    category: [lemmatize_text(kw) for kw in keywords]\n",
    "    for category, keywords in categories.items()\n",
    "}\n",
    "\n",
    "print(lemmatized_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7381958",
   "metadata": {},
   "source": [
    "### Booking dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56eb65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_booking.head(10000)\n",
    "\n",
    "df_lemmatized = df_test.with_columns([\n",
    "    pl.col(\"review_positive\").map_elements(lemmatize_text).alias(\"review_positive\"),\n",
    "    pl.col(\"review_negative\").map_elements(lemmatize_text).alias(\"review_negative\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16997ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Category Count ===\n",
      "\n",
      "pets: 185\n",
      "\n",
      "=== Keyword Details ===\n",
      "\n",
      "dog: 102\n",
      "pet: 33\n",
      "bird: 18\n",
      "cat: 16\n",
      "animal: 8\n",
      "pup: 4\n",
      "rabbit: 2\n",
      "dog bowl: 1\n",
      "pet - friendly: 1\n",
      "animal allow: 0\n",
      "cat - friendly: 0\n",
      "dog - friendly: 0\n",
      "ferret: 0\n",
      "hamster: 0\n",
      "pet welcome: 0\n",
      "\n",
      "=== Preview of Filtered DataFrame ===\n",
      "Size of dataset 125\n"
     ]
    }
   ],
   "source": [
    "# Concatenate both review columns into a single text column for counting/filtering\n",
    "df_lemmatized = df_lemmatized.with_columns(\n",
    "    (pl.col(\"review_positive\") + \" \" + pl.col(\"review_negative\")).alias(\"text\")\n",
    ")\n",
    "\n",
    "# Initialize dictionaries for counts\n",
    "keyword_summary = {}\n",
    "category_summary = {}\n",
    "\n",
    "# List to store filtered rows\n",
    "filtered_rows = []\n",
    "\n",
    "for category, keywords in lemmatized_categories.items():\n",
    "    category_total = 0\n",
    "    # Create a regex for the category\n",
    "    regex = r\"\\b(\" + \"|\".join(re.escape(kw).replace(\"\\\\-\", \"[-\\\\s]\").replace(\"\\\\ \", \"\\\\s+\") for kw in keywords) + r\")\\b\"\n",
    "\n",
    "    # Filter rows containing at least one keyword\n",
    "    matches = df_lemmatized.filter(pl.col(\"text\").str.contains(regex))\n",
    "\n",
    "    # Function to identify which keywords are found in each comment\n",
    "    def find_keywords(text):\n",
    "        found = [kw for kw in keywords if re.search(r\"\\b\" + re.escape(kw).replace(\"\\\\ \", \"\\\\s+\") + r\"\\b\", text)]\n",
    "        return \", \".join(found)\n",
    "\n",
    "    # Add a new column with the keywords found\n",
    "    matches = matches.with_columns(\n",
    "        pl.col(\"text\").map_elements(find_keywords).alias(\"keywords_found\")\n",
    "    )\n",
    "\n",
    "    # Append to the list of filtered rows\n",
    "    filtered_rows.append(matches)\n",
    "\n",
    "    # Count keyword occurrences\n",
    "    for kw in keywords:\n",
    "        count = (\n",
    "            df_lemmatized\n",
    "            .select(pl.col(\"text\").str.count_matches(r\"\\b\" + re.escape(kw).replace(\"\\\\ \", \"\\\\s+\") + r\"\\b\").sum().alias(\"total\"))\n",
    "            .item()\n",
    "        )\n",
    "        keyword_summary[kw] = int(count)\n",
    "        category_total += count\n",
    "    category_summary[category] = int(category_total)\n",
    "\n",
    "# Concatenate all filtered rows into a new DataFrame\n",
    "df_filtered = pl.concat(filtered_rows)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n=== Category Count ===\\n\")\n",
    "for cat, count in category_summary.items():\n",
    "    print(f\"{cat}: {count}\")\n",
    "\n",
    "print(\"\\n=== Keyword Details ===\\n\")\n",
    "for kw, count in sorted(keyword_summary.items(), key=lambda x: (-x[1], x[0])):\n",
    "    print(f\"{kw}: {count}\")\n",
    "\n",
    "print(\"\\n=== Preview of Filtered DataFrame ===\")\n",
    "print(\"Size of dataset\", df_filtered.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3179cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the new dataset\n",
    "df_filtered.write_csv(\"../data/processed/data_pet_booking.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb54a7",
   "metadata": {},
   "source": [
    "### Yelp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "253e83b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_yelp.head(10000)\n",
    "\n",
    "df_lemmatized = df_test.with_columns(\n",
    "    pl.col(\"text\").map_elements(lemmatize_text).alias(\"text\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b243d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Category Count ===\n",
      "\n",
      "pets: 511\n",
      "\n",
      "=== Keyword Details ===\n",
      "\n",
      "dog: 287\n",
      "pet: 56\n",
      "bird: 47\n",
      "cat: 46\n",
      "animal: 34\n",
      "rabbit: 27\n",
      "pup: 11\n",
      "dog - friendly: 3\n",
      "animal allow: 0\n",
      "cat - friendly: 0\n",
      "dog bowl: 0\n",
      "ferret: 0\n",
      "hamster: 0\n",
      "pet - friendly: 0\n",
      "pet welcome: 0\n",
      "\n",
      "=== Preview of Filtered DataFrame ===\n",
      "Size of dataset 277\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries for counts\n",
    "keyword_summary = {}\n",
    "category_summary = {}\n",
    "\n",
    "# List to store filtered rows\n",
    "filtered_rows = []\n",
    "\n",
    "for category, keywords in lemmatized_categories.items():\n",
    "    category_total = 0\n",
    "    # Create a regex for the category\n",
    "    regex = r\"\\b(\" + \"|\".join(re.escape(kw).replace(\"\\\\-\", \"[-\\\\s]\").replace(\"\\\\ \", \"\\\\s+\") for kw in keywords) + r\")\\b\"\n",
    "\n",
    "    # Filter rows containing at least one keyword\n",
    "    matches = df_lemmatized.filter(pl.col(\"text\").str.contains(regex))\n",
    "\n",
    "    # Function to identify which keywords are found in each comment\n",
    "    def find_keywords(text):\n",
    "        found = [kw for kw in keywords if re.search(r\"\\b\" + re.escape(kw).replace(\"\\\\ \", \"\\\\s+\") + r\"\\b\", text)]\n",
    "        return \", \".join(found)\n",
    "\n",
    "    # Add a new column with the keywords found\n",
    "    matches = matches.with_columns(\n",
    "        pl.col(\"text\").map_elements(find_keywords).alias(\"keywords_found\")\n",
    "    )\n",
    "\n",
    "    # Append to the list of filtered rows\n",
    "    filtered_rows.append(matches)\n",
    "\n",
    "    # Count keyword occurrences\n",
    "    for kw in keywords:\n",
    "        count = (\n",
    "            df_lemmatized\n",
    "            .select(pl.col(\"text\").str.count_matches(r\"\\b\" + re.escape(kw).replace(\"\\\\ \", \"\\\\s+\") + r\"\\b\").sum().alias(\"total\"))\n",
    "            .item()\n",
    "        )\n",
    "        keyword_summary[kw] = int(count)\n",
    "        category_total += count\n",
    "    category_summary[category] = int(category_total)\n",
    "\n",
    "# Concatenate all filtered rows into a new DataFrame\n",
    "df_filtered = pl.concat(filtered_rows)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n=== Category Count ===\\n\")\n",
    "for cat, count in category_summary.items():\n",
    "    print(f\"{cat}: {count}\")\n",
    "\n",
    "print(\"\\n=== Keyword Details ===\\n\")\n",
    "for kw, count in sorted(keyword_summary.items(), key=lambda x: (-x[1], x[0])):\n",
    "    print(f\"{kw}: {count}\")\n",
    "\n",
    "print(\"\\n=== Preview of Filtered DataFrame ===\")\n",
    "print(\"Size of dataset\", df_filtered.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "650d5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the new dataset\n",
    "df_filtered.write_csv(\"../data/processed/data_pet_yelp.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
