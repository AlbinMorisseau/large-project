{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b3fdb94",
   "metadata": {},
   "source": [
    "# Pipeline preprocessing test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106525e",
   "metadata": {},
   "source": [
    "Once you have managed the anomalies and created a clean dataset, you now need to create a pipeline that allows you to extract three datasets based on content from a total dataset:\n",
    "- pets dataset\n",
    "- children dataset\n",
    "- disability dataset\n",
    "\n",
    "To do this, several steps must be carried out:\n",
    "- stop word removal\n",
    "- tokenize the text\n",
    "- lemmatize the text\n",
    "- extract keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d4eb448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import polars as pl\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a0685adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "\n",
    "NUM_THREADS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb6d447",
   "metadata": {},
   "source": [
    "## Stop word removal and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a93b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "NEGATIONS = {\"not\", \"no\", \"never\", \"none\", \"cannot\", \"can't\", \"don't\", \n",
    "             \"doesn't\", \"isn't\", \"wasn't\", \"weren't\", \"wouldn't\", \"shouldn't\", \"couldn't\"}\n",
    "\n",
    "def remove_stopwords(df: pl.DataFrame, column_name: str) -> pl.DataFrame:\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    def clean_text(text: str) -> str:\n",
    "        if not isinstance(text, str):\n",
    "            return text\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        # Garde les mots avec lettres ou tirets et conserve les négations\n",
    "        filtered = [word for word in tokens if re.match(r\"^[A-Za-z-]+$\", word) \n",
    "                    and (word not in stop_words or word in NEGATIONS)]\n",
    "        return \" \".join(filtered)\n",
    "\n",
    "    return df.with_columns(\n",
    "        pl.col(column_name).map_elements(clean_text, return_dtype=pl.Utf8).alias(column_name)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985458e7",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2788d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import polars as pl\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load SpaCy (disable unnecessary components for faster performance)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "\n",
    "def lemmatize_and_clean_texts(\n",
    "    texts: List[str],\n",
    "    batch_size: int = 2000,\n",
    "    n_process: int = 4\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Lemmatize a list of texts using spaCy with multiprocessing\n",
    "    and clean them for keyword matching.\n",
    "    \n",
    "    Cleaning:\n",
    "    - Replace \" - \" with \"-\" to handle multi-word keywords like \"pet-friendly\".\n",
    "    - Strip leading/trailing whitespace.\n",
    "    \"\"\"\n",
    "    clean_texts = [(t if isinstance(t, str) else \"\") for t in texts]\n",
    "    lemmatized = []\n",
    "    for doc in nlp.pipe(clean_texts, batch_size=batch_size, n_process=n_process):\n",
    "        text = \" \".join([token.lemma_ for token in doc])\n",
    "        text = text.replace(\" - \", \"-\").strip()\n",
    "        lemmatized.append(text)\n",
    "    return lemmatized\n",
    "\n",
    "\n",
    "def lemmatize_column_fast(\n",
    "    df: pl.DataFrame, \n",
    "    col_name: str, \n",
    "    new_col_name: str = None, \n",
    "    chunk_size: int = 5000, \n",
    "    n_process: int = 4\n",
    ") -> pl.DataFrame:\n",
    "    new_col_name = new_col_name or f\"{col_name}_lemmatized\"\n",
    "    texts = df.select(col_name).to_series().to_list()\n",
    "    lemmatized_chunks = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), chunk_size), desc=f\"Lemmatizing {col_name}\"):\n",
    "        chunk = texts[i:i + chunk_size]\n",
    "        lemmatized_chunks.extend(lemmatize_and_clean_texts(chunk, n_process=n_process))\n",
    "\n",
    "    return df.with_columns(pl.Series(name=new_col_name, values=lemmatized_chunks))\n",
    "\n",
    "\n",
    "def lemmatize_categories(\n",
    "    categories: Dict[str, List[str]]\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Lemmatize all keywords in category dictionary and clean them\n",
    "    using lemmatize_and_clean_texts.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        category: lemmatize_and_clean_texts(keywords, batch_size=100, n_process=1)\n",
    "        for category, keywords in categories.items()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cea9ebe",
   "metadata": {},
   "source": [
    "## Keywords extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d2b0044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import concurrent.futures\n",
    "from typing import Dict, List\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_all_categories(\n",
    "    df: pl.DataFrame,\n",
    "    col_name: str,\n",
    "    categories: Dict[str, List[str]],\n",
    "    exclusions: Dict[str, List[str]] = None,\n",
    "    n_process: int = 4,\n",
    "    id_col: str = \"id\"\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract reviews matching category keywords, keeping reviews if at least one keyword remains\n",
    "    after temporarily removing exclusion phrases.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Input dataframe.\n",
    "        col_name (str): Column containing the text.\n",
    "        categories (Dict[str, List[str]]): {category: [lemmatized keywords]}.\n",
    "        exclusions (Dict[str, List[str]]): {category: [phrases to exclude]}.\n",
    "        n_process (int): Number of threads.\n",
    "        id_col (str): Column containing unique IDs.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame with columns [id, review, keywords_found, category].\n",
    "    \"\"\"\n",
    "\n",
    "    texts = df.select([id_col, col_name]).to_pandas()\n",
    "    exclusions = exclusions or {}\n",
    "\n",
    "    def normalize_keyword(kw: str) -> str:\n",
    "        return kw.strip().replace(\" - \", \"-\")\n",
    "\n",
    "    def make_regex(kw: str) -> str:\n",
    "        kw = normalize_keyword(kw)\n",
    "        if \" \" in kw or \"-\" in kw:\n",
    "            return re.escape(kw).replace(\"\\\\-\", \"[-\\\\s]\").replace(\"\\\\ \", \"\\\\s+\")\n",
    "        else:\n",
    "            return r\"\\b\" + re.escape(kw) + r\"\\b\"\n",
    "\n",
    "    def process_category(category: str, keywords: List[str], excluded_phrases: List[str]):\n",
    "        results = []\n",
    "        for _, row in texts.iterrows():\n",
    "            text = row[col_name]\n",
    "            review_id = row[id_col]\n",
    "            if not isinstance(text, str):\n",
    "                continue\n",
    "\n",
    "            temp_text = text\n",
    "            # Supprimer temporairement les phrases d'exclusion\n",
    "            if excluded_phrases:\n",
    "                for ex in excluded_phrases:\n",
    "                    temp_text = re.sub(make_regex(ex), \" \", temp_text, flags=re.IGNORECASE)\n",
    "\n",
    "            # Vérifier si au moins un mot clé reste\n",
    "            matched_keywords = [kw for kw in keywords if re.search(make_regex(kw), temp_text, flags=re.IGNORECASE)]\n",
    "\n",
    "            if matched_keywords:\n",
    "                results.append((review_id, text, \", \".join(matched_keywords), category))\n",
    "\n",
    "        return results\n",
    "\n",
    "    # Parallel processing\n",
    "    all_results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=n_process) as executor:\n",
    "        futures = {executor.submit(process_category, cat, kws, exclusions.get(cat, [])): cat\n",
    "                   for cat, kws in categories.items()}\n",
    "        for fut in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Keyword extraction\"):\n",
    "            all_results.extend(fut.result())\n",
    "\n",
    "    if not all_results:\n",
    "        return pl.DataFrame(schema={\n",
    "            id_col: pl.Int64,\n",
    "            \"review\": pl.Utf8,\n",
    "            \"keywords_found\": pl.Utf8,\n",
    "            \"category\": pl.Utf8\n",
    "        })\n",
    "\n",
    "    df_filtered = pl.DataFrame({\n",
    "        id_col: [r[0] for r in all_results],\n",
    "        \"review\": [r[1] for r in all_results],\n",
    "        \"keywords_found\": [r[2] for r in all_results],\n",
    "        \"category\": [r[3] for r in all_results]\n",
    "    })\n",
    "\n",
    "    print(f\"Extracted {df_filtered.shape[0]} matching reviews across {len(categories)} categories.\")\n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466c933f",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "032da963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (33, 2)\n",
      "┌─────┬─────────────────────────────────┐\n",
      "│ id  ┆ review                          │\n",
      "│ --- ┆ ---                             │\n",
      "│ i64 ┆ str                             │\n",
      "╞═════╪═════════════════════════════════╡\n",
      "│ 1   ┆ I love traveling with my dog    │\n",
      "│ 2   ┆ I really like travel with my c… │\n",
      "│ 3   ┆ Our cat always comes with us o… │\n",
      "│ 4   ┆ Pet-friendly hotels make our v… │\n",
      "│ 5   ┆ We brought our hamster along    │\n",
      "│ …   ┆ …                               │\n",
      "│ 29  ┆ Join the handicap sports club   │\n",
      "│ 30  ┆ Handicap insurance coverage is… │\n",
      "│ 31  ┆ Disabled access forum was info… │\n",
      "│ 32  ┆ Handicap rating system is conf… │\n",
      "│ 33  ┆  Sport and weight lift          │\n",
      "└─────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "data = [\n",
    "    # PET - vrais positifs\n",
    "    \"I love traveling with my dog\",\n",
    "    \"I really like travel with my cat and my child\",\n",
    "    \"Our cat always comes with us on trips\",\n",
    "    \"Pet-friendly hotels make our vacation easier\",\n",
    "    \"We brought our hamster along\",\n",
    "    \"Birds are not allowed, but our parrot joined\",\n",
    "    \"The hot dog was amazing but my dog was very tired so we decided to go home\",\n",
    "    \n",
    "    # PET - faux positifs à exclure\n",
    "    \"I ate a hot dog at the festival\",\n",
    "    \"Investing time in my pet project is fun\",\n",
    "    \"The doctor recommended a PET scan\",\n",
    "    \"The patient had a cat scan yesterday\",\n",
    "    \"Dogecoin prices are rising fast\",\n",
    "    \n",
    "    # CHILD - vrais positifs\n",
    "    \"We need a crib for our baby\",\n",
    "    \"Childcare services at the hotel are great\",\n",
    "    \"Kids menu available at the restaurant\",\n",
    "    \"High chair provided in our room\",\n",
    "    \"Playground nearby is perfect for toddlers\",\n",
    "    \n",
    "    # CHILD - faux positifs à exclure\n",
    "    \"I remember my childhood fondly\",\n",
    "    \"Use the child lock on the door\",\n",
    "    \"Childproof cabinets are essential\",\n",
    "    \"Childhood memories last forever\",\n",
    "    \"Child's play area is empty\",\n",
    "    \n",
    "    # HANDICAP - vrais positifs\n",
    "    \"Wheelchair access is very important\",\n",
    "    \"Elevator and ramps help disabled travelers\",\n",
    "    \"Accessible toilet in the lobby\",\n",
    "    \"Hearing aid support available\",\n",
    "    \"Visual impairment guide for tourists\",\n",
    "    \n",
    "    # HANDICAP - faux positifs à exclure\n",
    "    \"Handicap parking spots are limited\",\n",
    "    \"Join the handicap sports club\",\n",
    "    \"Handicap insurance coverage is sufficient\",\n",
    "    \"Disabled access forum was informative\",\n",
    "    \"Handicap rating system is confusing\",\n",
    "    \" Sport and weight lift\"\n",
    "]\n",
    "\n",
    "df_test = pl.DataFrame({\n",
    "    \"id\": range(1, len(data) + 1),\n",
    "    \"review\": data\n",
    "})\n",
    "\n",
    "print(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "17ea3906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Lemmatized Categories ===\n",
      "\n",
      "=== Lemmatized Exclusions ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lemmatizing review: 100%|██████████| 1/1 [00:23<00:00, 23.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DataFrame with Lemmatized Texts ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword extraction: 100%|██████████| 3/3 [00:01<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 431 matching reviews across 3 categories.\n",
      "\n",
      "=== Filtered Reviews ===\n",
      "shape: (10, 4)\n",
      "┌─────┬─────────────────────────────────┬────────────────┬──────────┐\n",
      "│ id  ┆ review                          ┆ keywords_found ┆ category │\n",
      "│ --- ┆ ---                             ┆ ---            ┆ ---      │\n",
      "│ i64 ┆ str                             ┆ str            ┆ str      │\n",
      "╞═════╪═════════════════════════════════╪════════════════╪══════════╡\n",
      "│ 59  ┆ location good accessible many … ┆ accessible     ┆ handicap │\n",
      "│ 158 ┆ room superb enjoy living room … ┆ elevator       ┆ handicap │\n",
      "│ 170 ┆ conveniently locate beautiful … ┆ accessible     ┆ handicap │\n",
      "│ 181 ┆ excellent location quiet still… ┆ elevator       ┆ handicap │\n",
      "│ 226 ┆ excellent location bar open am… ┆ lift           ┆ handicap │\n",
      "│ 284 ┆ clean compact double bed room … ┆ accessible     ┆ handicap │\n",
      "│ 332 ┆ location cute design theme roo… ┆ lift           ┆ handicap │\n",
      "│ 337 ┆ apartment close gold coast con… ┆ elevator       ┆ handicap │\n",
      "│ 347 ┆ swimming pool cafe breakfast n… ┆ lift           ┆ handicap │\n",
      "│ 359 ┆ bright modern reception desk l… ┆ lift           ┆ handicap │\n",
      "└─────┴─────────────────────────────────┴────────────────┴──────────┘\n",
      "DataFrame saved to ../../data/processed/booking_test_key_word_test_a_supprimer.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    df = pl.read_csv(\"../../data/original/dataset/data_booking.csv\").head(5000)\n",
    "    nb_process = NUM_THREADS\n",
    "    name_column = \"review\"\n",
    "    output_path = \"../../data/processed/booking_test_key_word_test_a_supprimer.csv\"\n",
    "\n",
    "    categories = {\n",
    "        \"handicap\": [\n",
    "            \"handicap\", \"wheelchair\", \"accessible\", \"braille\", \"ramp\", \"lift\", \"elevator\",\n",
    "            \"disabled\", \"barrier-free\", \"accessible toilet\", \"toilet accessible\",\n",
    "            \"mobility aid\", \"adapted\", \"hearing aid\", \"visual impairment\", \"accessible entrance\"\n",
    "        ],\n",
    "        \"pet\": [\n",
    "            \"dog\", \"cat\", \"pet\", \"animal\", \"rabbit\", \"hamster\", \"ferret\", \"bird\",\n",
    "            \"pet-friendly\", \"animals allowed\", \"dog-friendly\", \"cat-friendly\",\n",
    "            \"pet welcome\", \"pup\", \"dog bowl\"\n",
    "        ],\n",
    "        \"child\": [\n",
    "            \"child\", \"baby\", \"kid\", \"stroller\", \"son\", \"daughter\", \"toddler\",\n",
    "            \"infant\", \"playground\", \"high chair\", \"changing table\", \"family-friendly\",\n",
    "            \"childcare\", \"kids menu\", \"baby seat\", \"family\",\"baby bed\", \"cot\", \"crib\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    exclusions = {\n",
    "        \"pet\": [\n",
    "            \"hot dog\",          \n",
    "            \"dogecoin\",         \n",
    "            \"corn dog\",\n",
    "            \"dog day\",          \n",
    "            \"pet project\",      \n",
    "            \"cat scan\", \n",
    "            \"pet scan\",               \n",
    "        ],\n",
    "        \"child\": [\n",
    "            \"childhood\",\n",
    "        ],\n",
    "        \"handicap\": [\n",
    "            \"weight lift\",      \n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "    df_clean = remove_stopwords(df, name_column)\n",
    "\n",
    "    lemmatized_categories = lemmatize_categories(categories)\n",
    "    print(\"\\n=== Lemmatized Categories ===\")\n",
    "\n",
    "    lemmatized_exclusions = lemmatize_categories(exclusions)\n",
    "    print(\"\\n=== Lemmatized Exclusions ===\")\n",
    "\n",
    "    df_lem = lemmatize_column_fast(df_clean, name_column, n_process=4)\n",
    "    print(\"\\n=== DataFrame with Lemmatized Texts ===\")\n",
    "\n",
    "    df_keywords = extract_all_categories(\n",
    "        df_lem, \n",
    "        col_name = f\"{name_column}_lemmatized\",\n",
    "        categories=lemmatized_categories,\n",
    "        exclusions=lemmatized_exclusions,\n",
    "        n_process=nb_process\n",
    "    )\n",
    "         \n",
    "    print(\"\\n=== Filtered Reviews ===\")\n",
    "    print(df_keywords.head(10))\n",
    "\n",
    "    # Sauvegarde\n",
    "    df_keywords.write_csv(output_path)\n",
    "    print(f\"DataFrame saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5fd13e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'handicap': ['handicap', 'wheelchair', 'accessible', 'braille', 'ramp', 'lift', 'elevator', 'disable', 'barrier-free', 'accessible toilet', 'toilet accessible', 'mobility aid', 'adapt', 'hear aid', 'visual impairment', 'accessible entrance'], 'pet': ['dog', 'cat', 'pet', 'animal', 'rabbit', 'hamster', 'ferret', 'bird', 'pet-friendly', 'animal allow', 'dog-friendly', 'cat-friendly', 'pet welcome', 'pup', 'dog bowl'], 'child': ['child', 'baby', 'kid', 'stroller', 'son', 'daughter', 'toddler', 'infant', 'playground', 'high chair', 'change table', 'family-friendly', 'childcare', 'kids menu', 'baby seat', 'family', 'baby bed', 'cot', 'crib']}\n"
     ]
    }
   ],
   "source": [
    "print(lemmatized_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1ad3dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5_000, 18)\n",
      "┌────────────┬────────────┬────────────┬────────────┬───┬───────────┬──────┬───────────┬───────────┐\n",
      "│ review_tit ┆ review_sco ┆ review_hel ┆ guest_type ┆ … ┆ location_ ┆ id   ┆ review    ┆ review_le │\n",
      "│ le         ┆ re         ┆ pful_votes ┆ ---        ┆   ┆ is_city_c ┆ ---  ┆ ---       ┆ mmatized  │\n",
      "│ ---        ┆ ---        ┆ ---        ┆ str        ┆   ┆ enter     ┆ i64  ┆ str       ┆ ---       │\n",
      "│ str        ┆ f64        ┆ i64        ┆            ┆   ┆ ---       ┆      ┆           ┆ str       │\n",
      "│            ┆            ┆            ┆            ┆   ┆ i64       ┆      ┆           ┆           │\n",
      "╞════════════╪════════════╪════════════╪════════════╪═══╪═══════════╪══════╪═══════════╪═══════════╡\n",
      "│ null       ┆ 7.0        ┆ 0          ┆ Couple     ┆ … ┆ 1         ┆ 1    ┆ beautiful ┆ beautiful │\n",
      "│            ┆            ┆            ┆            ┆   ┆           ┆      ┆ bathroom  ┆ bathroom  │\n",
      "│            ┆            ┆            ┆            ┆   ┆           ┆      ┆ comfortab ┆ comfortab │\n",
      "│            ┆            ┆            ┆            ┆   ┆           ┆      ┆ le…       ┆ le…       │\n",
      "│ Fantastic  ┆ 8.0        ┆ 0          ┆ Family     ┆ … ┆ 0         ┆ 2    ┆ null      ┆           │\n",
      "│ location   ┆            ┆            ┆ with       ┆   ┆           ┆      ┆           ┆           │\n",
      "│ and        ┆            ┆            ┆ children   ┆   ┆           ┆      ┆           ┆           │\n",
      "│ servic…    ┆            ┆            ┆            ┆   ┆           ┆      ┆           ┆           │\n",
      "│ Great      ┆ 7.0        ┆ 0          ┆ Couple     ┆ … ┆ 0         ┆ 3    ┆ central   ┆ central   │\n",
      "│ central    ┆            ┆            ┆            ┆   ┆           ┆      ┆ location  ┆ location  │\n",
      "│ location   ┆            ┆            ┆            ┆   ┆           ┆      ┆ friendly  ┆ friendly  │\n",
      "│            ┆            ┆            ┆            ┆   ┆           ┆      ┆ help…     ┆ help…     │\n",
      "│ Great      ┆ 8.0        ┆ 0          ┆ Couple     ┆ … ┆ 0         ┆ 4    ┆ room      ┆ room      │\n",
      "│ place in a ┆            ┆            ┆            ┆   ┆           ┆      ┆ spacious  ┆ spacious  │\n",
      "│ great      ┆            ┆            ┆            ┆   ┆           ┆      ┆ king size ┆ king size │\n",
      "│ locatio…   ┆            ┆            ┆            ┆   ┆           ┆      ┆ bed co…   ┆ bed co…   │\n",
      "│ Fantastic  ┆ 10.0       ┆ 0          ┆ Family     ┆ … ┆ 1         ┆ 5    ┆ perfect   ┆ perfect   │\n",
      "│ find       ┆            ┆            ┆ with       ┆   ┆           ┆      ┆ every way ┆ every     │\n",
      "│            ┆            ┆            ┆ children   ┆   ┆           ┆      ┆ - close   ┆ way-close │\n",
      "│            ┆            ┆            ┆            ┆   ┆           ┆      ┆ stat…     ┆ statio…   │\n",
      "│ …          ┆ …          ┆ …          ┆ …          ┆ … ┆ …         ┆ …    ┆ …         ┆ …         │\n",
      "│ The host   ┆ 10.0       ┆ 0          ┆ Couple     ┆ … ┆ 0         ┆ 4996 ┆ null      ┆           │\n",
      "│ was super  ┆            ┆            ┆            ┆   ┆           ┆      ┆           ┆           │\n",
      "│ attentive  ┆            ┆            ┆            ┆   ┆           ┆      ┆           ┆           │\n",
      "│ a…         ┆            ┆            ┆            ┆   ┆           ┆      ┆           ┆           │\n",
      "│ null       ┆ 9.0        ┆ 0          ┆ Solo       ┆ … ┆ 1         ┆ 4997 ┆ super     ┆ super     │\n",
      "│            ┆            ┆            ┆ traveller  ┆   ┆           ┆      ┆ clean     ┆ clean     │\n",
      "│            ┆            ┆            ┆            ┆   ┆           ┆      ┆ room      ┆ room      │\n",
      "│            ┆            ┆            ┆            ┆   ┆           ┆      ┆ modern    ┆ modern    │\n",
      "│            ┆            ┆            ┆            ┆   ┆           ┆      ┆ amp sp…   ┆ amp sp…   │\n",
      "│ null       ┆ 10.0       ┆ 0          ┆ Group      ┆ … ┆ 0         ┆ 4998 ┆ null      ┆           │\n",
      "│ null       ┆ 9.0        ┆ 0          ┆ Family     ┆ … ┆ 0         ┆ 4999 ┆ bed       ┆ bed       │\n",
      "│            ┆            ┆            ┆ with       ┆   ┆           ┆      ┆ shower    ┆ shower    │\n",
      "│            ┆            ┆            ┆ children   ┆   ┆           ┆      ┆ great     ┆ great     │\n",
      "│            ┆            ┆            ┆            ┆   ┆           ┆      ┆ view      ┆ view      │\n",
      "│            ┆            ┆            ┆            ┆   ┆           ┆      ┆ window    ┆ window    │\n",
      "│ null       ┆ 10.0       ┆ 0          ┆ Group      ┆ … ┆ 0         ┆ 5000 ┆ null      ┆           │\n",
      "└────────────┴────────────┴────────────┴────────────┴───┴───────────┴──────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b325409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_title  review_score  \\\n",
      "0                                                None           7.0   \n",
      "1                     Fantastic location and  service           8.0   \n",
      "2                              Great central location           7.0   \n",
      "3                     Great place in a great location           8.0   \n",
      "4                                      Fantastic find          10.0   \n",
      "5                                                None           8.0   \n",
      "6                                                None           7.0   \n",
      "7                                                None          10.0   \n",
      "8                                        Perfect stay          10.0   \n",
      "9                              Annual happy vacation.           9.0   \n",
      "10  Would definitely recommend for families. And w...          10.0   \n",
      "11                                               None          10.0   \n",
      "12   Book this apartment in Palermo:)It is worth it:)          10.0   \n",
      "13  Great location and staff. Some restaurants nee...           8.0   \n",
      "14                                               None          10.0   \n",
      "\n",
      "    review_helpful_votes            guest_type guest_country  room_nights  \\\n",
      "0                      0                Couple           Zuc            1   \n",
      "1                      0  Family with children          Made            5   \n",
      "2                      0                Couple         Xazas            2   \n",
      "3                      0                Couple        Nukeye            3   \n",
      "4                      0  Family with children         Mejok            1   \n",
      "5                      2        Solo traveller           Kiy           10   \n",
      "6                      0                Couple         Mejok            1   \n",
      "7                      0                Couple         Qehoj            4   \n",
      "8                      0                Couple           Nen            2   \n",
      "9                      0                Couple           Vey            2   \n",
      "10                     0  Family with children         Xazas            7   \n",
      "11                     0        Solo traveller           Vig            1   \n",
      "12                     0  Family with children          Keyu            2   \n",
      "13                     0  Family with children           Zuc            3   \n",
      "14                     0  Family with children          Tuhi            1   \n",
      "\n",
      "    month  accommodation_id accommodation_type     accommodation_country  \\\n",
      "0       9        -548048990              Hotel                 Australia   \n",
      "1       9        1225335718  Bed and Breakfast              South Africa   \n",
      "2      12       -1296112659         ApartHotel               New Zealand   \n",
      "3      10       -2104338227              Hotel  United States of America   \n",
      "4       9         -42373088  Bed and Breakfast                     Italy   \n",
      "5       9        -569946669              Hotel                    Canada   \n",
      "6       9        1424214619              Hotel                     Spain   \n",
      "7       8       -2134029912             Hostel                   Bolivia   \n",
      "8       8        1784421235              Hotel                   Georgia   \n",
      "9       9        1089067999              Hotel                     Egypt   \n",
      "10     10       -1495523991             Resort              Cook Islands   \n",
      "11      9         -68596877              Hotel                    Greece   \n",
      "12      9        1509558485          Apartment                     Italy   \n",
      "13      9        1615437840             Resort  United States of America   \n",
      "14      9        -184353094          Apartment                    Poland   \n",
      "\n",
      "    accommodation_score  accommodation_star_rating  location_is_ski  \\\n",
      "0                   8.7                        4.5                0   \n",
      "1                   7.9                        0.0                0   \n",
      "2                   8.2                        0.0                0   \n",
      "3                   7.5                        2.0                0   \n",
      "4                   8.5                        0.0                0   \n",
      "5                   8.1                        4.0                0   \n",
      "6                   7.2                        2.0                0   \n",
      "7                   9.2                        0.0                0   \n",
      "8                   9.5                        4.0                1   \n",
      "9                   8.2                        4.0                0   \n",
      "10                  7.5                        4.0                0   \n",
      "11                  9.1                        3.0                0   \n",
      "12                  9.9                        0.0                0   \n",
      "13                  8.1                        4.0                0   \n",
      "14                  9.6                        0.0                0   \n",
      "\n",
      "    location_is_beach  location_is_city_center  id  \\\n",
      "0                   0                        1   1   \n",
      "1                   0                        0   2   \n",
      "2                   1                        0   3   \n",
      "3                   0                        0   4   \n",
      "4                   0                        1   5   \n",
      "5                   0                        1   6   \n",
      "6                   1                        0   7   \n",
      "7                   0                        0   8   \n",
      "8                   0                        0   9   \n",
      "9                   1                        0  10   \n",
      "10                  1                        0  11   \n",
      "11                  0                        0  12   \n",
      "12                  0                        0  13   \n",
      "13                  1                        0  14   \n",
      "14                  1                        0  15   \n",
      "\n",
      "                                               review  \n",
      "0   beautiful bathroom comfortable bed no robes pr...  \n",
      "1                                                None  \n",
      "2   central location friendly helpful staff no air...  \n",
      "3   room spacious king size bed comfortable enjoye...  \n",
      "4   perfect every way - close station friendly hos...  \n",
      "5   great location really nice room good breakfast...  \n",
      "6                                                None  \n",
      "7                                                None  \n",
      "8   say enough amazing stay loved facility view fo...  \n",
      "9   staff friendly breakfast exceptional location ...  \n",
      "10  staff awesome lot exciting activities kids res...  \n",
      "11  general fantastic stay great price ok admit lu...  \n",
      "12                                               None  \n",
      "13  great location great staff great pools fountai...  \n",
      "14                                               None  \n"
     ]
    }
   ],
   "source": [
    "print(df_clean.head(15).to_pandas())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
