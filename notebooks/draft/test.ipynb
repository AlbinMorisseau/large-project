{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35959954",
   "metadata": {},
   "source": [
    "# Nuage de mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c84b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import polars as pl\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#df = pl.read_csv(\"../data/processed/data_pet_booking.csv\")\n",
    "df = pl.read_csv(\"../data/processed/data_pet_yelp.csv\")\n",
    "# --- 1. Exemple de corpus de reviews ---\n",
    "reviews = df.select(\"text\").to_series().to_list()\n",
    "\n",
    "# --- 2. Combiner toutes les reviews en une seule cha√Æne ---\n",
    "text = \" \".join(reviews)\n",
    "\n",
    "# --- 3. D√©finir les mots √† ignorer (stopwords) ---\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Add supplementary words\n",
    "custom_stopwords = {\"get\", \"could\", \"take\", \"know\", \"make\", \"go\", \"give\", \"would\", \"also\", \"even\", \"say\", \"try\"}\n",
    "stop_words.update(custom_stopwords)\n",
    "\n",
    "# --- 4. Cr√©er le Word Cloud ---\n",
    "wordcloud = WordCloud(width=800, height=400,\n",
    "                      background_color='black',\n",
    "                      stopwords=stop_words,\n",
    "                      max_words=30).generate(text)\n",
    "\n",
    "# --- 5. Afficher le Word Cloud ---\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Reviews about pets\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a8d356",
   "metadata": {},
   "source": [
    "# mod√®le BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c623aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7da5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae701c",
   "metadata": {},
   "source": [
    "## Classification avec RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0972b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "import polars as pl\n",
    "\n",
    "# Charger un mod√®le adapt√© (RoBERTa est tr√®s bon ici)\n",
    "pipe = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\"\n",
    ")\n",
    "\n",
    "# Tes labels\n",
    "labels = [\"pet\", \"child\", \"handicap\", \"other\"]\n",
    "\n",
    "# Exemple de reviews\n",
    "df = pl.read_csv(\"../data/processed/data_handicap_booking.csv\")\n",
    "# --- 1. Exemple de corpus de reviews ---\n",
    "reviews = df.select(\"review_negative\").head(5).to_series().to_list()\n",
    "\n",
    "# Classification\n",
    "for r in reviews:\n",
    "    result = pipe(r, candidate_labels=labels, multi_label=False)\n",
    "    print(f\"\\nTexte : {r}\")\n",
    "    print(f\"‚Üí Cat√©gorie pr√©dite : {result['labels'][0]} (score={result['scores'][0]:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8208b9b1",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93614d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "translated = GoogleTranslator(source='auto', target='en').translate(\"albin cat faire √† manger et il sera avec son chien\") \n",
    "print(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel translation\n",
    "\n",
    "import polars as pl\n",
    "from deep_translator import GoogleTranslator\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "df = pl.read_csv(\"../data/original/Booking/val.csv\")\n",
    "\n",
    "texts = df[\"review_positive\"].head(50).to_list()\n",
    "\n",
    "translator = GoogleTranslator(source='auto', target='en')\n",
    "\n",
    "def translate_one(t):\n",
    "    try:\n",
    "        return translator.translate(t)\n",
    "    except Exception as e:\n",
    "        return f\"[ERROR: {e}]\"\n",
    "\n",
    "# Parallelisation (ex: 8 threads)\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    results = list(executor.map(translate_one, texts))\n",
    "\n",
    "df_result = pl.DataFrame({\n",
    "    \"translated_text\": results\n",
    "})\n",
    "\n",
    "print(df_result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0cb366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Compter combien de fois chaque review appara√Æt par dataset\n",
    "df_counts = (\n",
    "    df.group_by([\"original_dataset\", \"review\"])\n",
    "      .agg(pl.len().alias(\"count\"))\n",
    ")\n",
    "\n",
    "# 2. Filtrer pour ne garder que les reviews qui apparaissent plus d'une fois\n",
    "df_duplicates = df_counts.filter(pl.col(\"count\") > 1)\n",
    "\n",
    "# 3. R√©sumer : total de doublons par dataset\n",
    "df_summary = (\n",
    "    df_duplicates.group_by(\"original_dataset\")\n",
    "                 .agg(pl.sum(\"count\").alias(\"total_duplicates\"))\n",
    "                 .sort(\"original_dataset\")\n",
    ")\n",
    "\n",
    "print(df_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# 1Ô∏è‚É£ Supprimer les reviews vides\n",
    "df_non_empty = df.filter(pl.col(\"review\").str.strip_chars() != \"\")\n",
    "\n",
    "# 2Ô∏è‚É£ Compter les occurrences de chaque review par dataset\n",
    "df_counts = (\n",
    "    df_non_empty.group_by([\"review\", \"original_dataset\"])\n",
    "                .agg(pl.len().alias(\"count\"))\n",
    ")\n",
    "\n",
    "# 3Ô∏è‚É£ Pour chaque review, trouver le dataset o√π elle appara√Æt le plus\n",
    "df_max_dataset = (\n",
    "    df_counts.sort([\"review\", \"count\"], descending=[False, True])\n",
    "             .group_by(\"review\")\n",
    "             .agg([\n",
    "                 pl.first(\"original_dataset\").alias(\"most_common_dataset\"),\n",
    "                 pl.max(\"count\").alias(\"max_count\")\n",
    "             ])\n",
    ")\n",
    "\n",
    "print(df_max_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa912565",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = df_max_dataset.select(pl.max(\"max_count\")).item()\n",
    "df_max_dataset.filter(pl.col(\"max_count\") == max_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0545ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5 = df_max_dataset.sort(\"max_count\", descending=True).head(15)\n",
    "\n",
    "print(top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66849cb4",
   "metadata": {},
   "source": [
    "## Language identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10eb2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text = [\n",
    "    \"Brevity is the soul of wit.\",\n",
    "    \"Amor, ch'a nullo amato amar perdona.\"\n",
    "]\n",
    "\n",
    "model_ckpt = \"papluca/xlm-roberta-base-language-detection\"\n",
    "pipe = pipeline(\"text-classification\", model=model_ckpt)\n",
    "pipe(df, top_k=1, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18687538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "df = pl.read_csv(\"../data/processed/all_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb26c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.select(\"review\").head(10)[\"review\"].to_list()\n",
    "pipe(texts, top_k =1, truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import polars as pl\n",
    "\n",
    "# Charger le mod√®le de d√©tection de langue\n",
    "model_ckpt = \"papluca/xlm-roberta-base-language-detection\"\n",
    "pipe = pipeline(\"text-classification\", model=model_ckpt)\n",
    "\n",
    "df = df.head(1000)\n",
    "\n",
    "# 1Ô∏è‚É£ Convertir la colonne Polars en liste Python\n",
    "texts = df.select(\"review\")[\"review\"].to_list()\n",
    "\n",
    "# 2Ô∏è‚É£ Appliquer le pipeline\n",
    "results = pipe(texts, top_k=1, truncation=True)\n",
    "\n",
    "# 3Ô∏è‚É£ Extraire les labels dominants\n",
    "langs = [r[0][\"label\"] for r in results]\n",
    "\n",
    "# 4Ô∏è‚É£ Ajouter les r√©sultats dans le DataFrame Polars\n",
    "df = df.with_columns(pl.Series(\"detected_lang\", langs))\n",
    "\n",
    "# 5Ô∏è‚É£ Compter le nombre de textes par langue\n",
    "counts = df.group_by(\"detected_lang\").agg(\n",
    "    pl.len().alias(\"nb_texts\")\n",
    ")\n",
    "\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import polars as pl\n",
    "from tqdm import tqdm  # barre de progression\n",
    "\n",
    "# Charger le mod√®le\n",
    "model_ckpt = \"papluca/xlm-roberta-base-language-detection\"\n",
    "pipe = pipeline(\"text-classification\", model=model_ckpt)\n",
    "\n",
    "df = df.head(1000)\n",
    "\n",
    "# Param√®tre : taille de batch\n",
    "batch_size = 100\n",
    "\n",
    "all_langs = []\n",
    "num_rows = df.height\n",
    "\n",
    "# 1Ô∏è‚É£ Traitement par batch avec barre de progression\n",
    "for i in tqdm(range(0, num_rows, batch_size), desc=\"D√©tection de langue\"):\n",
    "    batch_texts = df[i:i+batch_size, \"review\"].to_list()\n",
    "    batch_results = pipe(batch_texts, top_k=1, truncation=True)\n",
    "    batch_langs = [r[0][\"label\"] for r in batch_results]\n",
    "    all_langs.extend(batch_langs)\n",
    "\n",
    "# 2Ô∏è‚É£ Ajouter la colonne d√©tect√©e au DataFrame\n",
    "df = df.with_columns(pl.Series(\"detected_lang\", all_langs))\n",
    "\n",
    "# 3Ô∏è‚É£ Compter le nombre de textes par langue\n",
    "counts = df.group_by(\"detected_lang\").agg(\n",
    "    pl.len().alias(\"nb_texts\")\n",
    ").sort(\"nb_texts\", descending=True)\n",
    "\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7941b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi threading test\n",
    "from transformers import pipeline\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Charger le mod√®le\n",
    "model_ckpt = \"papluca/xlm-roberta-base-language-detection\"\n",
    "pipe = pipeline(\"text-classification\", model=model_ckpt)\n",
    "\n",
    "# Exemple : on limite √† 1000 lignes pour le test\n",
    "df = df.head(1000)\n",
    "\n",
    "# Param√®tres\n",
    "batch_size = 100\n",
    "num_threads = 4  # nombre de threads √† utiliser\n",
    "\n",
    "# Fonction pour traiter un batch de textes\n",
    "def process_batch(batch_texts):\n",
    "    results = pipe(batch_texts, top_k=1, truncation=True)\n",
    "    return [r[0][\"label\"] for r in results]\n",
    "\n",
    "# 1Ô∏è‚É£ Cr√©er les batches\n",
    "batches = [df[i:i+batch_size, \"review\"].to_list() for i in range(0, df.height, batch_size)]\n",
    "\n",
    "all_langs = []\n",
    "\n",
    "# 2Ô∏è‚É£ Multithreading avec ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    # soumettre tous les batches\n",
    "    futures = {executor.submit(process_batch, batch): batch for batch in batches}\n",
    "\n",
    "    # r√©cup√©ration des r√©sultats avec barre de progression\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"D√©tection de langue\"):\n",
    "        batch_langs = future.result()\n",
    "        all_langs.extend(batch_langs)\n",
    "\n",
    "# 3Ô∏è‚É£ Ajouter la colonne d√©tect√©e au DataFrame\n",
    "df = df.with_columns(pl.Series(\"detected_lang\", all_langs))\n",
    "\n",
    "# 4Ô∏è‚É£ Compter le nombre de textes par langue\n",
    "counts = df.group_by(\"detected_lang\").agg(\n",
    "    pl.len().alias(\"nb_texts\")\n",
    ").sort(\"nb_texts\", descending=True)\n",
    "\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test avec langid pour accelerer le processus\n",
    "import polars as pl\n",
    "import langid\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Fonction pour identifier la langue d'une review\n",
    "def detect_lang(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return None\n",
    "    lang, score = langid.classify(text)\n",
    "    return lang\n",
    "\n",
    "# Param√®tres\n",
    "num_threads = 4  # nombre de threads √† utiliser\n",
    "texts = df[\"review\"].to_list()\n",
    "\n",
    "# 1Ô∏è‚É£ Parallelisation avec ThreadPoolExecutor\n",
    "all_langs = []\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    # tqdm pour la barre de progression\n",
    "    for result in tqdm(executor.map(detect_lang, texts), total=len(texts), desc=\"D√©tection de langue\"):\n",
    "        all_langs.append(result)\n",
    "\n",
    "# 2Ô∏è‚É£ Ajouter la colonne d√©tect√©e au DataFrame Polars\n",
    "df = df.with_columns(pl.Series(\"detected_lang\", all_langs))\n",
    "\n",
    "# 3Ô∏è‚É£ Compter le nombre de textes par langue\n",
    "counts = df.group_by(\"detected_lang\").agg(\n",
    "    pl.len().alias(\"nb_texts\")\n",
    ").sort(\"nb_texts\", descending=True)\n",
    "\n",
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379230ff",
   "metadata": {},
   "source": [
    "## M√©thode pour accelerer encore plus les processus ( a regarder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa7ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import polars as pl\n",
    "import langid\n",
    "from tqdm import tqdm\n",
    "\n",
    "def detect_language_parallel_optimized(df: pl.DataFrame, column_name: str, num_processes: int = None, batch_size: int = 50000) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Detect the language of a text column in a Polars DataFrame using langid in parallel with ProcessPoolExecutor and batching.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Input DataFrame.\n",
    "        column_name (str): Name of the text column to process.\n",
    "        num_processes (int): Number of processes to use for parallel processing (default: all available cores).\n",
    "        batch_size (int): Number of rows per batch (default=50_000).\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: New DataFrame with an added column 'detected_lang' containing language codes.\n",
    "    \"\"\"\n",
    "    if num_processes is None:\n",
    "        import multiprocessing\n",
    "        num_processes = multiprocessing.cpu_count()\n",
    "\n",
    "    def detect_lang(texts):\n",
    "        \"\"\"Detect language for a list of texts.\"\"\"\n",
    "        return [langid.classify(t)[0] if isinstance(t, str) and t.strip() else None for t in texts]\n",
    "\n",
    "    all_langs = []\n",
    "\n",
    "    for i in tqdm(range(0, df.height, batch_size), desc=\"Language detection (batched)\"):\n",
    "        batch_texts = df[i:i+batch_size, column_name].to_list()\n",
    "        with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "            # submit one batch to a process\n",
    "            future = executor.submit(detect_lang, batch_texts)\n",
    "            all_langs.extend(future.result())\n",
    "\n",
    "    # Return new DataFrame with added column\n",
    "    return df.with_columns(pl.Series(\"detected_lang\", all_langs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c301cb29",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28220cb3",
   "metadata": {},
   "source": [
    "LDA est un mod√®le bay√©sien qui d√©compose un corpus en topics latents, chacun repr√©sent√© par un ensemble de mots, et attribue √† chaque document une proportion de ces topics. C‚Äôest l‚Äôoutil classique pour le topic modeling non supervis√©.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3836f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis.gensim_models\n",
    "import pyLDAvis\n",
    "import polars as pl\n",
    "\n",
    "# --- 0. Pr√©paration nltk ---\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# --- 1. Corpus exemple ---\n",
    "df = pl.read_csv(\"../data/processed/key_word_test_a_supprimer.csv\")\n",
    "df = df.head(50)\n",
    "documents = df[\"review\"].to_list()\n",
    "\n",
    "\n",
    "# --- 2. Nettoyage et tokenisation ---\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [t for t in tokens if t.isalpha() and t not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "texts = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# --- 3. Cr√©er le dictionnaire et corpus pour LDA ---\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# --- 4. Entra√Æner le mod√®le LDA ---\n",
    "num_topics = 3  # on suppose 2 topics dans ce corpus\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=42, passes=15)\n",
    "\n",
    "# --- 5. Afficher les topics ---\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Topic {idx}: {topic}\")\n",
    "\n",
    "# --- 6. Visualisation interactive ---\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.show(vis)  # ouvrira une page web interactive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1a52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be31d5f0",
   "metadata": {},
   "source": [
    "Resultat style mais inutile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c53e45",
   "metadata": {},
   "source": [
    "# Synonymous research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ecb21",
   "metadata": {},
   "source": [
    "C'est possible de trouver des synonymes √† l'aide de la biblioth√®que nltk. Cela fonctionne g√©n√©ralement sur des mots simples, mais cela reste une bonne premi√®re √©tape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a09f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")  # pour avoir des synonymes en anglais\n",
    "\n",
    "categories = {\n",
    "    \"handicap\": [\n",
    "        \"handicap\", \"wheelchair\", \"accessible\", \"braille\", \"ramp\", \"lift\", \"elevator\",\n",
    "        \"disabled\", \"barrier-free\", \"accessible toilet\", \"toilet accessible\",\n",
    "        \"mobility aid\", \"adapted\", \"hearing aid\", \"visual impairment\", \"accessible entrance\"\n",
    "    ],\n",
    "    \"pet\": [\n",
    "        \"dog\", \"cat\", \"pet\", \"animal\", \"rabbit\", \"hamster\", \"ferret\", \"bird\",\n",
    "        \"pet-friendly\", \"animals allowed\", \"dog-friendly\", \"cat-friendly\",\n",
    "        \"pet welcome\", \"pup\", \"dog bowl\"\n",
    "    ],\n",
    "    \"child\": [\n",
    "        \"child\", \"baby\", \"kid\", \"stroller\", \"son\", \"daughter\", \"toddler\",\n",
    "        \"infant\", \"playground\", \"high chair\", \"changing table\", \"family-friendly\",\n",
    "        \"childcare\", \"kids menu\", \"baby seat\", \"family\",\"baby bed\", \"cot\", \"crib\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            # exclure les underscores et majuscules\n",
    "            clean_word = lemma.name().replace(\"_\", \" \").lower()\n",
    "            if clean_word != word.lower():\n",
    "                synonyms.add(clean_word)\n",
    "    return list(synonyms)\n",
    "\n",
    "categories_with_synonyms = {}\n",
    "for cat, words in categories.items():\n",
    "    expanded = set(words)  # inclure les mots d'origine\n",
    "    for w in words:\n",
    "        syns = get_synonyms(w)\n",
    "        expanded.update(syns)\n",
    "    categories_with_synonyms[cat] = list(expanded)\n",
    "\n",
    "# Affichage d'un exemple\n",
    "for cat, words in categories_with_synonyms.items():\n",
    "    print(f\"{cat}: {words}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb21c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_synonyms(categories_with_synonyms, max_per_line=8):\n",
    "    for cat, words in categories_with_synonyms.items():\n",
    "        print(f\"\\n=== {cat.upper()} ===\")\n",
    "        sorted_words = sorted(words)\n",
    "        line = \"\"\n",
    "        for i, w in enumerate(sorted_words, 1):\n",
    "            line += f\"{w}, \"\n",
    "            if i % max_per_line == 0:\n",
    "                print(line[:-2])  # enl√®ve la derni√®re virgule\n",
    "                line = \"\"\n",
    "        if line:  # imprime le reste\n",
    "            print(line[:-2])\n",
    "\n",
    "# Exemple d'utilisation\n",
    "print_synonyms(categories_with_synonyms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d189b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prompt vLLM G√©n√©r√© ---\n",
      "### SYSTEM INSTRUCTION ###\n",
      "You are a strict business-travel-review classifier. Your task is to analyze a review and determine whether the traveler(s) have any type of handicap or if the reviews contains a specific needs associated with a disability (transporations, amenities, etc.). Respond strictly with 'yes' if the review indicates a handicaped traveler or a special need related to handicap travelling, or 'no' if not. ONE word only, no explanations or extra text.\n",
      "\n",
      "### EXAMPLES ###\n",
      "Here are some examples:\n",
      "Review: \"Plant to go to London in September Need information about Accessible Van in London airport\" -> yes\n",
      "Review: \"The room was great, big enough to move around in my power chair in both the bedroom and bathroom\" -> yes\n",
      "Review: \"I would like to sell my wheelchair.please contact me\" -> no\n",
      "Review: \"It's new digital travel magazine targeted exclusively for travelers with disabilities.\" -> no\n",
      "Review: \"Nice roll-in shower with a pull-down bench, but the amenities were again too high\" -> yes\n",
      "\n",
      "### CLASSIFICATION TASK ###\n",
      "Now classify this review:\n",
      "\"I chose to stay here on the basis of a previous W Hotel experience which was fantastic. I have to admit that I was left slightly disappointed. The location itself could not be better for the Washington sights and metro, but the service leaves something to be desired. If you wish to take advantage of the complimentary drop off service (within 5 miles), book well in advance to avoid long waiting times which can mess up your day. (We ended up taking a taxi).\n",
      "There are two entrances to the hotel and I instinctively opted for the one without a ramp (!) and had to drag my luggage up the stairs. There was no-one to help me or even hold the door open. Had I chosen the other door, there was a ramp but on another occasion, despite the doorman, I still received no help at all.\n",
      "The foyer had a display of pop art, to which I have no objection, but it rendered it feeling extremely busy and over cluttered. It also hid the check-in desk behind, which didn't help whilst dragging my luggage around! I also noted an interesting complimentary drink available near the foyer bar area but it was always empty throughout my stay so I sadly never had the opportunity to sample it.\n",
      "We waited for quite some time to check in, which can happen and I, again, have no objection to that. However, what did leave me feeling irritated was the complete lack of acknowledgement despite three members of staff directly in front of us. Eventually, a lovely gentleman who I assume was the manager or supervisor, saw us waiting and gave us a quick apology and assured us that we would be seen to asap. He saved his staff on several other occasions during our stay. \n",
      "We also had problems during check-out, and again when we returned to collect our luggage. Due to the lack of space, there was a limited waiting area and we were repeatedly queue jumped by other more aggressive hotel clients. The W staff were oblivious to the growing anger of their more polite customers around them. Not a good start - or finish - to our stay.\n",
      "We stayed in a 'wonderful' room - the most basic, with an internal view. Since we spent much of our time out and about, this didn't bother us. For peace and quiet in DC, request a room as high up as possible to avoid noise. I was annoyed that, despite requesting this on booking, I had to re-request on check-in, although it was changed with no qualms. Our room was on the 7th floor and we had no problems. As always with W hotels, the room was cleverly designed and luxurious. The photos don't really do it justice. No faults there at all.. although it would have been nice for such a large hotel chain to acknowledge our wedding anniversary while we were there. Other, often smaller hotels have either upgraded us, given us a little something extra in the room, or even just wished us a happy anniversary.\n",
      "With a keen interest in bars and cocktails, we were intrigued to visit the highly rated 'POV' rooftop bar. The views over Washington are second to none but to call their house specialty cocktail a disappointment barely begins to cover it. I was horrified to watch the bar tender serve me a premix topped up with mixer. How can this possibly be a renowned cocktail bar in Washington?! Simple cocktail mistakes were also made behind the bar for other customers which were obvious to amateurs like us. If you are really interested in a true cocktail experience, I suggest you try 'The Passenger' (for which I have also written a review).\n",
      "Do try the J&G steakhouse for dinner. The food was delicious and service good.\n",
      "There is a 'Bliss' spa in the basement and a reasonably equipped gym, neither of which I had time to experience. One thing that was missing, however, was a jacuzzi/sauna for hotel client use. There is a steam room available within the spa but it is not advertised.\n",
      "Overall, the location and room were up to scratch, but as for the rest... what a shame.\" ->\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "def build_vllm_prompt(review_text: str) -> str:\n",
    "    # 1. Message System & Assistant (Instructions et Confirmation)\n",
    "    system_instruction = (\n",
    "        \"You are a strict business-travel-review classifier. Your task is to analyze a review and determine \"\n",
    "        \"whether the traveler(s) have any type of handicap or if the reviews contains a specific needs \"\n",
    "        \"associated with a disability (transporations, amenities, etc.). \"\n",
    "        \"Respond strictly with 'yes' if the review indicates a handicaped traveler or a special need related to handicap travelling, or 'no' if not. \"\n",
    "        \"ONE word only, no explanations or extra text.\"\n",
    "    )\n",
    "    \n",
    "    # 2. Exemples (Contextualisation)\n",
    "    examples = (\n",
    "        \"Here are some examples:\\n\"\n",
    "        \"Review: \\\"Plant to go to London in September Need information about Accessible Van in London airport\\\" -> yes\\n\"\n",
    "        \"Review: \\\"The room was great, big enough to move around in my power chair in both the bedroom and bathroom\\\" -> yes\\n\"\n",
    "        \"Review: \\\"I would like to sell my wheelchair.please contact me\\\" -> no\\n\"\n",
    "        \"Review: \\\"It's new digital travel magazine targeted exclusively for travelers with disabilities.\\\" -> no\\n\"\n",
    "        \"Review: \\\"Nice roll-in shower with a pull-down bench, but the amenities were again too high\\\" -> yes\"\n",
    "    )\n",
    "\n",
    "    # 3. La Question finale\n",
    "    question = f\"Now classify this review:\\n\\\"{review_text}\\\"\"\n",
    "    \n",
    "    # 4. Fusion du prompt complet (en utilisant des sauts de ligne clairs)\n",
    "    full_prompt = (\n",
    "        f\"### SYSTEM INSTRUCTION ###\\n{system_instruction}\\n\\n\"\n",
    "        f\"### EXAMPLES ###\\n{examples}\\n\\n\"\n",
    "        f\"### CLASSIFICATION TASK ###\\n{question} -> \" # Notez le \" -> \" √† la fin pour pr√©parer la r√©ponse\n",
    "    )\n",
    "    \n",
    "    return full_prompt.strip()\n",
    "\n",
    "# Exemple de revue √† classer\n",
    "review_text_to_test = \"\"\"I chose to stay here on the basis of a previous W Hotel experience which was fantastic. I have to admit that I was left slightly disappointed. The location itself could not be better for the Washington sights and metro, but the service leaves something to be desired. If you wish to take advantage of the complimentary drop off service (within 5 miles), book well in advance to avoid long waiting times which can mess up your day. (We ended up taking a taxi).\n",
    "There are two entrances to the hotel and I instinctively opted for the one without a ramp (!) and had to drag my luggage up the stairs. There was no-one to help me or even hold the door open. Had I chosen the other door, there was a ramp but on another occasion, despite the doorman, I still received no help at all.\n",
    "The foyer had a display of pop art, to which I have no objection, but it rendered it feeling extremely busy and over cluttered. It also hid the check-in desk behind, which didn't help whilst dragging my luggage around! I also noted an interesting complimentary drink available near the foyer bar area but it was always empty throughout my stay so I sadly never had the opportunity to sample it.\n",
    "We waited for quite some time to check in, which can happen and I, again, have no objection to that. However, what did leave me feeling irritated was the complete lack of acknowledgement despite three members of staff directly in front of us. Eventually, a lovely gentleman who I assume was the manager or supervisor, saw us waiting and gave us a quick apology and assured us that we would be seen to asap. He saved his staff on several other occasions during our stay. \n",
    "We also had problems during check-out, and again when we returned to collect our luggage. Due to the lack of space, there was a limited waiting area and we were repeatedly queue jumped by other more aggressive hotel clients. The W staff were oblivious to the growing anger of their more polite customers around them. Not a good start - or finish - to our stay.\n",
    "We stayed in a 'wonderful' room - the most basic, with an internal view. Since we spent much of our time out and about, this didn't bother us. For peace and quiet in DC, request a room as high up as possible to avoid noise. I was annoyed that, despite requesting this on booking, I had to re-request on check-in, although it was changed with no qualms. Our room was on the 7th floor and we had no problems. As always with W hotels, the room was cleverly designed and luxurious. The photos don't really do it justice. No faults there at all.. although it would have been nice for such a large hotel chain to acknowledge our wedding anniversary while we were there. Other, often smaller hotels have either upgraded us, given us a little something extra in the room, or even just wished us a happy anniversary.\n",
    "With a keen interest in bars and cocktails, we were intrigued to visit the highly rated 'POV' rooftop bar. The views over Washington are second to none but to call their house specialty cocktail a disappointment barely begins to cover it. I was horrified to watch the bar tender serve me a premix topped up with mixer. How can this possibly be a renowned cocktail bar in Washington?! Simple cocktail mistakes were also made behind the bar for other customers which were obvious to amateurs like us. If you are really interested in a true cocktail experience, I suggest you try 'The Passenger' (for which I have also written a review).\n",
    "Do try the J&G steakhouse for dinner. The food was delicious and service good.\n",
    "There is a 'Bliss' spa in the basement and a reasonably equipped gym, neither of which I had time to experience. One thing that was missing, however, was a jacuzzi/sauna for hotel client use. There is a steam room available within the spa but it is not advertised.\n",
    "Overall, the location and room were up to scratch, but as for the rest... what a shame.\"\"\"\n",
    "\n",
    "# Cr√©ation du prompt\n",
    "final_prompt = build_vllm_prompt(review_text_to_test)\n",
    "\n",
    "print(\"--- Prompt vLLM G√©n√©r√© ---\")\n",
    "print(final_prompt)\n",
    "print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Fonction pour construire le prompt (voir ci-dessus)\n",
    "# ==============================================================================\n",
    "def build_vllm_prompt(review_text: str) -> str:\n",
    "    # (Collez ici la fonction build_vllm_prompt de l'√âtape 1)\n",
    "    system_instruction = (...) # ...\n",
    "    examples = (...) # ...\n",
    "    question = f\"Now classify this review:\\n\\\"{review_text}\\\"\"\n",
    "    full_prompt = (\n",
    "        f\"### SYSTEM INSTRUCTION ###\\n{system_instruction}\\n\\n\"\n",
    "        f\"### EXAMPLES ###\\n{examples}\\n\\n\"\n",
    "        f\"### CLASSIFICATION TASK ###\\n{question} -> \"\n",
    "    )\n",
    "    return full_prompt.strip()\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Param√®tres de la Requ√™te\n",
    "# ==============================================================================\n",
    "API_URL = \"http://localhost:8000/generate\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "review_text_to_test = \"\"\"I chose to stay here on the basis of a previous W Hotel experience which was fantastic. I have to admit that I was left slightly disappointed. The location itself could not be better for the Washington sights and metro, but the service leaves something to be desired. If you wish to take advantage of the complimentary drop off service (within 5 miles), book well in advance to avoid long waiting times which can mess up your day. (We ended up taking a taxi).\n",
    "There are two entrances to the hotel and I instinctively opted for the one without a ramp (!) and had to drag my luggage up the stairs. There was no-one to help me or even hold the door open. Had I chosen the other door, there was a ramp but on another occasion, despite the doorman, I still received no help at all.\n",
    "The foyer had a display of pop art, to which I have no objection, but it rendered it feeling extremely busy and over cluttered. It also hid the check-in desk behind, which didn't help whilst dragging my luggage around! I also noted an interesting complimentary drink available near the foyer bar area but it was always empty throughout my stay so I sadly never had the opportunity to sample it.\n",
    "We waited for quite some time to check in, which can happen and I, again, have no objection to that. However, what did leave me feeling irritated was the complete lack of acknowledgement despite three members of staff directly in front of us. Eventually, a lovely gentleman who I assume was the manager or supervisor, saw us waiting and gave us a quick apology and assured us that we would be seen to asap. He saved his staff on several other occasions during our stay. \n",
    "We also had problems during check-out, and again when we returned to collect our luggage. Due to the lack of space, there was a limited waiting area and we were repeatedly queue jumped by other more aggressive hotel clients. The W staff were oblivious to the growing anger of their more polite customers around them. Not a good start - or finish - to our stay.\n",
    "We stayed in a 'wonderful' room - the most basic, with an internal view. Since we spent much of our time out and about, this didn't bother us. For peace and quiet in DC, request a room as high up as possible to avoid noise. I was annoyed that, despite requesting this on booking, I had to re-request on check-in, although it was changed with no qualms. Our room was on the 7th floor and we had no problems. As always with W hotels, the room was cleverly designed and luxurious. The photos don't really do it justice. No faults there at all.. although it would have been nice for such a large hotel chain to acknowledge our wedding anniversary while we were there. Other, often smaller hotels have either upgraded us, given us a little something extra in the room, or even just wished us a happy anniversary.\n",
    "With a keen interest in bars and cocktails, we were intrigued to visit the highly rated 'POV' rooftop bar. The views over Washington are second to none but to call their house specialty cocktail a disappointment barely begins to cover it. I was horrified to watch the bar tender serve me a premix topped up with mixer. How can this possibly be a renowned cocktail bar in Washington?! Simple cocktail mistakes were also made behind the bar for other customers which were obvious to amateurs like us. If you are really interested in a true cocktail experience, I suggest you try 'The Passenger' (for which I have also written a review).\n",
    "Do try the J&G steakhouse for dinner. The food was delicious and service good.\n",
    "There is a 'Bliss' spa in the basement and a reasonably equipped gym, neither of which I had time to experience. One thing that was missing, however, was a jacuzzi/sauna for hotel client use. There is a steam room available within the spa but it is not advertised.\n",
    "Overall, the location and room were up to scratch, but as for the rest... what a shame.\"\"\"\n",
    "\n",
    "final_prompt = build_vllm_prompt(review_text_to_test)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Construction du Payload (sans 'model')\n",
    "# ==============================================================================\n",
    "payload: Dict[str, Any] = {\n",
    "    \"prompt\": final_prompt,\n",
    "    \"max_tokens\": 1,           # Tr√®s faible pour forcer la r√©ponse en UN seul mot ('yes' ou 'no')\n",
    "    \"temperature\": 0.0,        # Temp√©rature basse pour une classification d√©terministe\n",
    "    \"stop\": [\"\\n\", \"\\r\"],      # Arr√™ter si le mod√®le g√©n√®re une nouvelle ligne apr√®s 'yes' ou 'no'\n",
    "}\n",
    "\n",
    "print(f\"Envoi de la requ√™te avec prompt de longueur: {len(final_prompt)} caract√®res.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. Envoi et Traitement\n",
    "# ==============================================================================\n",
    "try:\n",
    "    response = requests.post(API_URL, headers=HEADERS, data=json.dumps(payload))\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    # Extraction du texte (en utilisant la cl√© 'text' qui a fonctionn√© pour vous)\n",
    "    if 'text' in data and isinstance(data['text'], list) and data['text']:\n",
    "        raw_completion = data['text'][0]\n",
    "        \n",
    "        # Le mod√®le r√©pond avec le prompt + la classification, donc on ne garde que la fin\n",
    "        # On nettoie et on prend le premier mot\n",
    "        classification_result = raw_completion.replace(final_prompt, \"\").strip().split()[0].lower()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Classification R√©ussie :\")\n",
    "        print(f\"   Texte de la Revue : \\\"{review_text_to_test}\\\"\")\n",
    "        print(f\"   R√©sultat : **{classification_result}**\")\n",
    "    else:\n",
    "        print(\"\\nERREUR: La r√©ponse du mod√®le est vide ou a un format inattendu.\")\n",
    "        print(json.dumps(data, indent=4))\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"\\nüõë ERREUR DE CONNEXION: Assurez-vous que le serveur vLLM est d√©marr√©.\")\n",
    "    print(f\"D√©tails : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cd4f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import grequests\n",
    "import json\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# ==============================================================================\n",
    "# üõ†Ô∏è Configuration du Traitement\n",
    "# ==============================================================================\n",
    "INPUT_CSV_PATH = \"../../data/processed/data_validated/validated_data_accessiblego.csv\"\n",
    "REVIEW_COLUMN_NAME = \"review\"\n",
    "OUTPUT_CSV_PATH = \"reviews_classified_results.csv\"\n",
    "\n",
    "API_URL = \"http://localhost:8000/generate\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MAX_WORKERS = 32\n",
    "BATCH_SIZE = 250\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "    \"max_tokens\": 1,      \n",
    "    \"temperature\": 0.0,\n",
    "    \"stop\": [\"\\n\", \"\\r\"],\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# üß† Fonction de construction du prompt\n",
    "# ==============================================================================\n",
    "def build_vllm_prompt(review_text: str) -> str:\n",
    "    system_instruction = (\n",
    "        \"You are a strict review classifier. Your task is to analyze a review and determine \"\n",
    "        \"whether the traveler(s) have any type of handicap or if the reviews contains a specific needs \"\n",
    "        \"associated with a disability (transporations, amenities, etc.). \"\n",
    "        \"Respond strictly with 'yes' if the review indicates a handicaped traveler or a special need related to handicap travelling, or 'no' if not. \"\n",
    "        \"ONE word only, no explanations or extra text.\"\n",
    "    )\n",
    "    \n",
    "    examples = (\n",
    "        \"Here are some examples:\\n\"\n",
    "        \"Review: \\\"Plant to go to London in September Need information about Accessible Van in London airport\\\" -> yes\\n\"\n",
    "        \"Review: \\\"The room was great, big enough to move around in my power chair in both the bedroom and bathroom\\\" -> yes\\n\"\n",
    "        \"Review: \\\"I would like to sell my wheelchair.please contact me\\\" -> no\\n\"\n",
    "        \"Review: \\\"It's new digital travel magazine targeted exclusively for travelers with disabilities.\\\" -> no\\n\"\n",
    "        \"Review: \\\"Nice roll-in shower with a pull-down bench, but the amenities were again too high\\\" -> yes\"\n",
    "    )\n",
    "\n",
    "    question = f\"Now classify this review:\\n\\\"{review_text}\\\"\"\n",
    "    \n",
    "    full_prompt = (\n",
    "        f\"### SYSTEM INSTRUCTION ###\\n{system_instruction}\\n\\n\"\n",
    "        f\"### EXAMPLES ###\\n{examples}\\n\\n\"\n",
    "        f\"### CLASSIFICATION TASK ###\\n{question} -> \"\n",
    "    )\n",
    "    \n",
    "    return full_prompt.strip()\n",
    "\n",
    "# ==============================================================================\n",
    "# üîß Gestion d'Erreur Asynchrone\n",
    "# ==============================================================================\n",
    "def handle_exception(request, exception):\n",
    "    \"\"\"Fonction appel√©e par grequests en cas d'erreur r√©seau/timeout.\"\"\"\n",
    "    return None\n",
    "\n",
    "def process_batch(batch_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Envoie un lot de reviews √† l'API vLLM SIMULTAN√âMENT.\"\"\"\n",
    "    \n",
    "    # Stocker les donn√©es dans une structure s√©par√©e avec index\n",
    "    batch_rows = []\n",
    "    requests_to_send = []\n",
    "    \n",
    "    for idx, (index, row) in enumerate(batch_data.iterrows()):\n",
    "        original_row_copy = row.to_dict()\n",
    "        review_text = str(original_row_copy[REVIEW_COLUMN_NAME])\n",
    "        prompt = build_vllm_prompt(review_text)\n",
    "\n",
    "        payload = {\"prompt\": prompt, **MODEL_PARAMS}\n",
    "\n",
    "        req = grequests.post(\n",
    "            API_URL,\n",
    "            headers=HEADERS,\n",
    "            data=json.dumps(payload),\n",
    "            timeout=60,\n",
    "        )\n",
    "        \n",
    "        # Stocker les donn√©es s√©par√©ment avec un index de correspondance\n",
    "        batch_rows.append({\n",
    "            'index': idx,\n",
    "            'data': original_row_copy,\n",
    "            'prompt': prompt\n",
    "        })\n",
    "        requests_to_send.append(req)\n",
    "\n",
    "    # Envoi SIMULTAN√â de toutes les requ√™tes du lot\n",
    "    responses = grequests.map(requests_to_send, exception_handler=handle_exception, size=MAX_WORKERS)\n",
    "\n",
    "    results_list: List[Dict[str, Any]] = []\n",
    "\n",
    "    # Traitement des R√©ponses avec correspondance par index\n",
    "    for idx, response in enumerate(responses):\n",
    "        # R√©cup√©rer les donn√©es originales via l'index\n",
    "        if idx >= len(batch_rows):\n",
    "            continue\n",
    "            \n",
    "        current_row = batch_rows[idx]\n",
    "        current_data = current_row['data']\n",
    "        prompt_sent = current_row['prompt']\n",
    "        \n",
    "        classification = \"ERROR_UNSPECIFIED_PROCESSING\"\n",
    "\n",
    "        try:\n",
    "            # G√©rer les r√©ponses None (erreurs r√©seau)\n",
    "            if response is None:\n",
    "                classification = \"ERROR_NETWORK_TIMEOUT\"\n",
    "            else:\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "\n",
    "                if 'text' in data and data['text']:\n",
    "                    raw_completion = data['text'][0]\n",
    "                    # Nettoyage\n",
    "                    classification = raw_completion.replace(prompt_sent, \"\").strip().split()[0].lower()\n",
    "                else:\n",
    "                    classification = \"ERROR_FORMAT_NO_TEXT\"\n",
    "                    \n",
    "        except Exception as e:\n",
    "            classification = f\"ERROR_HTTP_{e.__class__.__name__}\"\n",
    "            \n",
    "        # Ajouter la classification √† la copie de la ligne originale\n",
    "        current_data['classification_result'] = classification\n",
    "        results_list.append(current_data)\n",
    "\n",
    "    return pd.DataFrame(results_list)\n",
    "\n",
    "# ==============================================================================\n",
    "# üèÉ Boucle d'Ex√©cution\n",
    "# ==============================================================================\n",
    "def run_inference_pipeline():\n",
    "    print(f\"Chargement du dataset depuis : {INPUT_CSV_PATH}\")\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_CSV_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"üõë ERREUR: Fichier introuvable √† {INPUT_CSV_PATH}. V√©rifiez le chemin.\")\n",
    "        return\n",
    "\n",
    "    if REVIEW_COLUMN_NAME not in df.columns:\n",
    "        print(f\"üõë ERREUR: Colonne '{REVIEW_COLUMN_NAME}' non trouv√©e dans le CSV.\")\n",
    "        print(f\"Colonnes disponibles : {list(df.columns)}\")\n",
    "        return\n",
    "\n",
    "    TOTAL_REVIEWS = len(df)\n",
    "    print(f\"Nombre total de reviews √† inf√©rer : {TOTAL_REVIEWS}\")\n",
    "\n",
    "    # Diviser le DataFrame en lots\n",
    "    list_of_batches = [df[i:i + BATCH_SIZE] for i in range(0, TOTAL_REVIEWS, BATCH_SIZE)]\n",
    "    print(f\"Divis√© en {len(list_of_batches)} lots de taille {BATCH_SIZE}.\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Utilisation d'un ThreadPoolExecutor pour l'ex√©cution parall√®le\n",
    "    all_results_dfs = []\n",
    "    \n",
    "    print(f\"\\nüöÄ D√©marrage de l'inf√©rence en lots s√©quentiels...\")\n",
    "    \n",
    "    for i, batch in enumerate(list_of_batches): # Parcourir les lots S√âQUENTIELLEMENT\n",
    "        try:\n",
    "            result_df = process_batch(batch) # Process_batch s'occupe des requ√™tes CONCURRENTES\n",
    "            all_results_dfs.append(result_df)\n",
    "            \n",
    "            # Affichage de la progression\n",
    "            if (i + 1) % 1 == 0: # Afficher √† chaque lot pour une boucle s√©quentielle\n",
    "                processed_count = min((i + 1) * BATCH_SIZE, TOTAL_REVIEWS)\n",
    "                progress_percent = (i + 1) / len(list_of_batches) * 100\n",
    "                elapsed = time.time() - start_time\n",
    "                speed = processed_count / elapsed if elapsed > 0 else 0\n",
    "                print(f\"Progression: {i + 1}/{len(list_of_batches)} lots ({progress_percent:.1f}%) | \"\n",
    "                      f\"{processed_count}/{TOTAL_REVIEWS} reviews | Vitesse: {speed:.1f} req/s\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Cette erreur g√®re les probl√®mes qui surviendraient DANS process_batch (hors grequests.map)\n",
    "            print(f\"‚ö†Ô∏è ERREUR CRITIQUE lors du traitement du lot {i}: {e}. Ce lot sera ignor√©.\")\n",
    "\n",
    "    if all_results_dfs:\n",
    "        final_df = pd.concat(all_results_dfs, ignore_index=True)\n",
    "        final_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"\\n--- Inf√©rence Termin√©e ---\")\n",
    "        print(f\"Total des reviews class√©es : {len(final_df)}\")\n",
    "        print(f\"Temps total √©coul√© : {end_time - start_time:.2f} secondes\")\n",
    "        print(f\"Vitesse moyenne : {len(final_df) / (end_time - start_time):.2f} requ√™tes/seconde\")\n",
    "        print(f\"‚úÖ R√©sultats sauvegard√©s dans : {OUTPUT_CSV_PATH}\")\n",
    "    else:\n",
    "        print(\"üõë AUCUN r√©sultat n'a √©t√© trait√©.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_inference_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c51033ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de valeurs pour yes :  1330\n",
      "Nombre de valeurs pour ERROR_HTTP_HTTPError :  25\n",
      "Nombre de valeurs pour no :  132\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "df_classified =  pd.read_csv(\"reviews_classified_results.csv\")\n",
    "\n",
    "unique_values = df_classified[\"classification_result\"]\n",
    "\n",
    "counter = Counter(unique_values)\n",
    "for k,v in counter.items():\n",
    "    print(f\"Nombre de valeurs pour {k} :  {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du dataset depuis : ../../data/processed/data_validated/validated_data_european_hotel_reviews.csv\n",
      "Nombre total de reviews √† inf√©rer : 15885\n",
      "Divis√© en 64 lots de taille 250.\n",
      "Syst√®me de Re-tentative activ√© : 3 tentatives max, d√©lai initial de 5s, Timeout de 180s.\n",
      "\n",
      "üöÄ D√©marrage de l'inf√©rence avec ThreadPoolExecutor...\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n",
      "  [ATTENTION] T√¢che √©chou√©e (ReadError, Tentative 1/3). Attente de 5.0s avant re-tentative.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import httpx\n",
    "import json\n",
    "import time\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "# ==============================================================================\n",
    "# üõ†Ô∏è Configuration du Traitement\n",
    "# ==============================================================================\n",
    "INPUT_CSV_PATH = \"../../data/processed/data_validated/validated_data_european_hotel_reviews.csv\"\n",
    "REVIEW_COLUMN_NAME = \"review\"\n",
    "OUTPUT_CSV_PATH = \"reviews_classified_results_async_retry.csv\"\n",
    "\n",
    "API_URL = \"http://localhost:8000/generate\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Param√®tres de concurrence (Ajust√©s pour r√©duire la saturation, √† re-tester apr√®s r√©glage de vLLM)\n",
    "MAX_CONCURRENT_REQUESTS = 18  # R√©duire la concurrence pour √©viter la saturation du pool vLLM\n",
    "MAX_WORKERS_THREADPOOL = 32   # Nombre de lots trait√©s en parall√®le\n",
    "BATCH_SIZE = 250             # Taille de lot r√©duite\n",
    "\n",
    "# Param√®tres de RE-TENTATIVE\n",
    "MAX_RETRIES = 3              # Nombre maximal de tentatives (1√®re tentative + 2 retries)\n",
    "BASE_RETRY_DELAY = 5         # D√©lai d'attente initial en secondes (Augment√© pour d√©saturer vLLM)\n",
    "TIMEOUT = 180                # D√©lai d'attente pour chaque requ√™te (Augment√© pour le ReadTimeout)\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "    \"max_tokens\": 1,\n",
    "    \"temperature\": 0.0,\n",
    "    \"stop\": [\"\\n\", \"\\r\"],\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# üß† Fonction de construction du prompt\n",
    "# ==============================================================================\n",
    "def build_vllm_prompt(review_text: str) -> str:\n",
    "    system_instruction = (\n",
    "        \"You are a strict business-travel-review classifier. Your task is to analyze a review and determine \"\n",
    "        \"whether the traveler(s) have any type of handicap or if the reviews contains a specific needs \"\n",
    "        \"associated with a disability (transporations, amenities, etc.). \"\n",
    "        \"Respond strictly with 'yes' if the review indicates a handicaped traveler or a special need related to handicap travelling, or 'no' if not. \"\n",
    "        \"ONE word only, no explanations or extra text.\"\n",
    "    )\n",
    "    \n",
    "    examples = (\n",
    "        \"Here are some examples:\\n\"\n",
    "        \"Review: \\\"Plant to go to London in September Need information about Accessible Van in London airport\\\" -> yes\\n\"\n",
    "        \"Review: \\\"The room was great, big enough to move around in my power chair in both the bedroom and bathroom\\\" -> yes\\n\"\n",
    "        \"Review: \\\"I would like to sell my wheelchair.please contact me\\\" -> no\\n\"\n",
    "        \"Review: \\\"It's new digital travel magazine targeted exclusively for travelers with disabilities.\\\" -> no\\n\"\n",
    "        \"Review: \\\"Nice roll-in shower with a pull-down bench, but the amenities were again too high\\\" -> yes\"\n",
    "    )\n",
    "\n",
    "    question = f\"Now classify this review:\\n\\\"{review_text}\\\"\"\n",
    "    \n",
    "    full_prompt = (\n",
    "        f\"### SYSTEM INSTRUCTION ###\\n{system_instruction}\\n\\n\"\n",
    "        f\"### EXAMPLES ###\\n{examples}\\n\\n\"\n",
    "        f\"### CLASSIFICATION TASK ###\\n{question} -> \"\n",
    "    )\n",
    "    \n",
    "    return full_prompt.strip()\n",
    "\n",
    "# ==============================================================================\n",
    "# üöÄ Fonctions Asynchrones (async/await)\n",
    "# ==============================================================================\n",
    "\n",
    "async def classify_single_review(\n",
    "    client: httpx.AsyncClient,\n",
    "    review_data: Dict[str, Any],\n",
    "    prompt: str,\n",
    ") -> Tuple[Dict[str, Any], str]:\n",
    "    \"\"\"Envoie une requ√™te asynchrone √† l'API vLLM avec un syst√®me de re-tentative.\"\"\"\n",
    "    \n",
    "    original_data = review_data.copy()\n",
    "    payload = {\"prompt\": prompt, **MODEL_PARAMS}\n",
    "    \n",
    "    # BOUCLE DE RE-TENTATIVE\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        classification = \"ERROR_UNSPECIFIED_PROCESSING\"\n",
    "        \n",
    "        try:\n",
    "            # 1. ENVOI DE LA REQU√äTE\n",
    "            response = await client.post(\n",
    "                API_URL,\n",
    "                headers=HEADERS,\n",
    "                json=payload,\n",
    "                timeout=TIMEOUT,\n",
    "            )\n",
    "            \n",
    "            # 2. V√âRIFICATION DU STATUT HTTP\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            # 3. TRAITEMENT DE LA R√âPONSE (Succ√®s)\n",
    "            if 'text' in data and data['text']:\n",
    "                raw_completion = data['text'][0]\n",
    "                classification = raw_completion.replace(prompt, \"\").strip().split()[0].lower()\n",
    "                # Sortie imm√©diate en cas de succ√®s\n",
    "                return original_data, classification\n",
    "            else:\n",
    "                classification = \"ERROR_FORMAT_NO_TEXT\"\n",
    "                # Erreur non r√©cup√©rable\n",
    "                return original_data, classification\n",
    "            \n",
    "        # 4. GESTION DES ERREURS R√âCUP√âRABLES\n",
    "        # Inclut ReadError, ReadTimeout, PoolTimeout (PoolTimeout est un type de TimeoutException dans httpx)\n",
    "        except (httpx.TimeoutException, httpx.ReadError, httpx.ConnectError) as e:\n",
    "            error_type = e.__class__.__name__\n",
    "            \n",
    "            if attempt < MAX_RETRIES - 1:\n",
    "                # Calcul du d√©lai d'attente exponentiel\n",
    "                delay = BASE_RETRY_DELAY * (2 ** attempt)\n",
    "                print(f\"  [ATTENTION] T√¢che √©chou√©e ({error_type}, Tentative {attempt + 1}/{MAX_RETRIES}). Attente de {delay:.1f}s avant re-tentative.\")\n",
    "                await asyncio.sleep(delay)\n",
    "                continue # Nouvelle tentative\n",
    "            else:\n",
    "                # √âchec apr√®s la derni√®re tentative\n",
    "                classification = f\"ERROR_FINAL_RECOVERABLE_{error_type}\"\n",
    "                return original_data, classification\n",
    "                \n",
    "        # 5. GESTION DES ERREURS NON R√âCUP√âRABLES\n",
    "        except httpx.HTTPStatusError as e:\n",
    "            classification = f\"ERROR_HTTP_{e.response.status_code}\"\n",
    "            return original_data, classification\n",
    "        \n",
    "        except Exception as e:\n",
    "            classification = f\"ERROR_EXCEPTION_{e.__class__.__name__}\"\n",
    "            return original_data, classification\n",
    "\n",
    "    return original_data, classification # Fallback\n",
    "\n",
    "\n",
    "async def process_batch_async(batch_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Cr√©e et ex√©cute toutes les t√¢ches asynchrones pour un lot.\"\"\"\n",
    "    \n",
    "    tasks = []\n",
    "    \n",
    "    # httpx.Limits est utilis√© pour contr√¥ler la concurrence au sein du lot.\n",
    "    limits = httpx.Limits(max_connections=MAX_CONCURRENT_REQUESTS, max_keepalive_connections=20)\n",
    "    \n",
    "    async with httpx.AsyncClient(limits=limits) as client:\n",
    "        for _, row in batch_data.iterrows():\n",
    "            review_text = str(row[REVIEW_COLUMN_NAME])\n",
    "            prompt = build_vllm_prompt(review_text)\n",
    "            \n",
    "            tasks.append(\n",
    "                classify_single_review(\n",
    "                    client=client,\n",
    "                    review_data=row.to_dict(),\n",
    "                    prompt=prompt,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Ex√©cution de toutes les requ√™tes du lot SIMULTAN√âMENT\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=False)\n",
    "        \n",
    "        results_list: List[Dict[str, Any]] = []\n",
    "        \n",
    "        for original_data, classification in results:\n",
    "            original_data['classification_result'] = classification\n",
    "            results_list.append(original_data)\n",
    "\n",
    "        return pd.DataFrame(results_list)\n",
    "\n",
    "\n",
    "def run_batch_in_loop(batch_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Ex√©cute la fonction asynchrone dans une boucle d'√©v√©nement.\"\"\"\n",
    "    return asyncio.run(process_batch_async(batch_data))\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# üèÉ Boucle d'Ex√©cution\n",
    "# ==============================================================================\n",
    "def run_inference_pipeline():\n",
    "    print(f\"Chargement du dataset depuis : {INPUT_CSV_PATH}\")\n",
    "    try:\n",
    "        df = pd.read_csv(INPUT_CSV_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"üõë ERREUR: Fichier introuvable √† {INPUT_CSV_PATH}. V√©rifiez le chemin.\")\n",
    "        return\n",
    "\n",
    "    if REVIEW_COLUMN_NAME not in df.columns:\n",
    "        print(f\"üõë ERREUR: Colonne '{REVIEW_COLUMN_NAME}' non trouv√©e dans le CSV.\")\n",
    "        print(f\"Colonnes disponibles : {list(df.columns)}\")\n",
    "        return\n",
    "\n",
    "    TOTAL_REVIEWS = len(df)\n",
    "    print(f\"Nombre total de reviews √† inf√©rer : {TOTAL_REVIEWS}\")\n",
    "\n",
    "    # Diviser le DataFrame en lots\n",
    "    list_of_batches = [df[i:i + BATCH_SIZE] for i in range(0, TOTAL_REVIEWS, BATCH_SIZE)]\n",
    "    print(f\"Divis√© en {len(list_of_batches)} lots de taille {BATCH_SIZE}.\")\n",
    "    print(f\"Syst√®me de Re-tentative activ√© : {MAX_RETRIES} tentatives max, d√©lai initial de {BASE_RETRY_DELAY}s, Timeout de {TIMEOUT}s.\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    all_results_dfs = []\n",
    "    \n",
    "    print(f\"\\nüöÄ D√©marrage de l'inf√©rence avec ThreadPoolExecutor...\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS_THREADPOOL) as executor:\n",
    "        # Soumettre tous les lots √† l'executor\n",
    "        future_to_batch = {executor.submit(run_batch_in_loop, batch): i for i, batch in enumerate(list_of_batches)}\n",
    "        \n",
    "        for future in future_to_batch:\n",
    "            batch_index = future_to_batch[future]\n",
    "            try:\n",
    "                # R√©cup√©rer le r√©sultat du lot\n",
    "                result_df = future.result() \n",
    "                all_results_dfs.append(result_df)\n",
    "                \n",
    "                # Affichage de la progression\n",
    "                processed_count = sum(len(df) for df in all_results_dfs)\n",
    "                progress_percent = processed_count / TOTAL_REVIEWS * 100\n",
    "                elapsed = time.time() - start_time\n",
    "                speed = processed_count / elapsed if elapsed > 0 else 0\n",
    "                \n",
    "                print(f\"Progression: {len(all_results_dfs)}/{len(list_of_batches)} lots ({progress_percent:.1f}%) | \"\n",
    "                      f\"{processed_count}/{TOTAL_REVIEWS} reviews | Vitesse: {speed:.1f} req/s\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è ERREUR CRITIQUE lors du traitement du lot {batch_index}: {e}. Ce lot sera ignor√©.\")\n",
    "                \n",
    "    if all_results_dfs:\n",
    "        final_df = pd.concat(all_results_dfs, ignore_index=True)\n",
    "        final_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"\\n--- Inf√©rence Termin√©e ---\")\n",
    "        print(f\"Total des reviews class√©es : {len(final_df)}\")\n",
    "        print(f\"Temps total √©coul√© : {end_time - start_time:.2f} secondes\")\n",
    "        print(f\"Vitesse moyenne : {len(final_df) / (end_time - start_time):.2f} requ√™tes/seconde\")\n",
    "        print(f\"‚úÖ R√©sultats sauvegard√©s dans : {OUTPUT_CSV_PATH}\")\n",
    "    else:\n",
    "        print(\"üõë AUCUN r√©sultat n'a √©t√© trait√©.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_inference_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a02bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "df_classified =  pd.read_csv(\"reviews_classified_results_async.csv\")\n",
    "\n",
    "unique_values = df_classified[\"classification_result\"]\n",
    "\n",
    "counter = Counter(unique_values)\n",
    "for k,v in counter.items():\n",
    "    print(f\"Nombre de valeurs pour {k} :  {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
